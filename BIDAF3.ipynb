{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc, random, math, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation, Dropout, Reshape, Flatten, Lambda, Permute\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import concatenate, Concatenate, multiply, Dot, dot\n",
    "from keras.layers import  GlobalMaxPooling1D, GlobalAveragePooling1D, Input, SpatialDropout1D, Bidirectional\n",
    "from keras.layers import CuDNNLSTM, CuDNNGRU, LSTM, GRU, Softmax\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 160000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen_p = 150 # max number of words in a context to use\n",
    "maxlen_q = 15 # max number of words in a question to use\n",
    "batch_size = 256\n",
    "num_rnn_units = 64\n",
    "num_hidden_units = 300\n",
    "drop_prob = 0.5\n",
    "max_norm = 5.0\n",
    "features = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = './data/train.tsv' # train set\n",
    "valid_path = './data/valid.tsv' # validation set\n",
    "test_path = './data/test.tsv' # test set\n",
    "embed_file = './sgns.target.word-ngram.1-2.dynwin5.thr10.neg5.dim300.iter5' # 预训练词向量\n",
    "train_feature_p_path = './data/train_fea_p.npy' # train passage word feature\n",
    "valid_feature_p_path = './data/valid_fea_p.npy' # validation passage word feature\n",
    "test_feature_p_path = './data/test_fea_p.npy' # test passage word feature\n",
    "train_feature_q_path = './data/train_fea_q.npy' # train passage word feature\n",
    "valid_feature_q_path = './data/valid_fea_q.npy' # validation passage word feature\n",
    "test_feature_q_path = './data/test_fea_q.npy' # test passage word feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000, 5) (90000, 5) (30000, 4)\n",
      "   id                                            passage  \\\n",
      "0   1  孩子 是 父母 的 一面镜子   由于 儿童 的 世界观 尚未 形成   他们 的 模仿 带...   \n",
      "1   1  孩子 是 父母 的 一面镜子   由于 儿童 的 世界观 尚未 形成   他们 的 模仿 带...   \n",
      "2   1  孩子 是 父母 的 一面镜子   由于 儿童 的 世界观 尚未 形成   他们 的 模仿 带...   \n",
      "3   2  目前   中国 很多 地方   学生 火车票 磁条 都 已经 升级 了   在 磁条 里 已...   \n",
      "4   2  目前   中国 很多 地方   学生 火车票 磁条 都 已经 升级 了   在 磁条 里 已...   \n",
      "\n",
      "                   query option  label  \n",
      "0   你 的 孩子 无法确定 保姆 带 大 的   无法确定      1  \n",
      "1      你 的 孩子 是 保姆 带 大 的      是      0  \n",
      "2     你 的 孩子 不是 保姆 带 大 的     不是      0  \n",
      "3  不是 一个 区间 刷 学生证 不能 有 票     不能      1  \n",
      "4   不是 一个 区间 刷 学生证 能 有 票      能      0  \n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(train_path, sep='\\t', header=0)\n",
    "valid = pd.read_csv(valid_path, sep='\\t', header=0)\n",
    "test = pd.read_csv(test_path, sep='\\t', header=0)\n",
    "print (train.shape, valid.shape, test.shape)\n",
    "print (train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000, 150, 2) (90000, 150, 2) (30000, 150, 2)\n",
      "(750000, 15, 2) (90000, 15, 2) (30000, 15, 2)\n"
     ]
    }
   ],
   "source": [
    "train_feature_p = np.load(train_feature_p_path)\n",
    "valid_feature_p = np.load(valid_feature_p_path)\n",
    "test_feature_p = np.load(test_feature_p_path)\n",
    "print (train_feature_p.shape, valid_feature_p.shape, test_feature_p.shape)\n",
    "train_feature_q = np.load(train_feature_q_path)\n",
    "valid_feature_q = np.load(valid_feature_q_path)\n",
    "test_feature_q = np.load(test_feature_q_path)\n",
    "print (train_feature_q.shape, valid_feature_q.shape, test_feature_q.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buld up the text input pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Fit the tokenizer on train, valid and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features, lower=True) \n",
    "\n",
    "tokenizer.fit_on_texts(pd.concat([train['passage'], train['query'], valid['passage'], valid['query'], test['passage'], test['query']], ignore_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1740000 167689\n"
     ]
    }
   ],
   "source": [
    "print (tokenizer.document_count, len(tokenizer.word_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text to seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tra_p = tokenizer.texts_to_sequences(train['passage'])\n",
    "tra_q = tokenizer.texts_to_sequences(train['query'])\n",
    "val_p = tokenizer.texts_to_sequences(valid['passage'])\n",
    "val_q = tokenizer.texts_to_sequences(valid['query'])\n",
    "te_p = tokenizer.texts_to_sequences(test['passage'])\n",
    "te_q = tokenizer.texts_to_sequences(test['query'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pad seq to maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_p = pad_sequences(tra_p, maxlen=maxlen_p)\n",
    "train_q = pad_sequences(tra_q, maxlen=maxlen_q, padding='post', truncating='post')\n",
    "valid_p = pad_sequences(val_p, maxlen=maxlen_p)\n",
    "valid_q = pad_sequences(val_q, maxlen=maxlen_q, padding='post', truncating='post')\n",
    "test_p = pad_sequences(te_p, maxlen=maxlen_p)\n",
    "test_q = pad_sequences(te_q, maxlen=maxlen_q, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000, 150) (750000, 15) (90000, 150) (90000, 15) (30000, 150) (30000, 15)\n"
     ]
    }
   ],
   "source": [
    "print (train_p.shape, train_q.shape, valid_p.shape, valid_q.shape, test_p.shape, test_q.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_l = train['label']\n",
    "valid_l = valid['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000,) (90000,)\n"
     ]
    }
   ],
   "source": [
    "print (train_l.shape, valid_l.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the pretrained word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.strip().split()) for o in open(embed_file, encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.014820942, 0.26983637)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embs = np.hstack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "emb_mean,emb_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words+1, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i > max_features: break\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.asarray(embedding_matrix, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attention_flow (x):\n",
    "    h = x[0]\n",
    "    u = x[1]\n",
    "    d = K.shape(h)[-1]\n",
    "    #print (K.sqrt(d))\n",
    "    s = K.batch_dot(h, K.permute_dimensions(u, (0,2,1)), axes=[2,1])/K.cast(d, 'float32') # [t, j]\n",
    "    p2q = K.batch_dot(K.softmax(s, axis=-1), u, axes=[2,1]) # [t, 2d]\n",
    "    b = K.softmax(K.max(s, axis=-1, keepdims=True), -2) # [t, 1]\n",
    "    q2p = K.tile(K.batch_dot(K.permute_dimensions(h, (0,2,1)), b, axes=[2,1]), [1, 1, K.int_shape(h)[1]]) # [2d, t]\n",
    "    h_p2q = multiply([h, p2q]) # [t, 2d]\n",
    "    h_q2p = multiply([h, K.permute_dimensions(q2p, (0,2,1))]) # [t, 2d]\n",
    "    g = concatenate([h, p2q, h_p2q, h_q2p]) # [t, 8d]\n",
    "    # self-attention\n",
    "    sg = K.batch_dot(g, K.permute_dimensions(g, (0,2,1)), axes=[2,1])/K.sqrt(4*d) # [t, t]\n",
    "    g = K.batch_dot(K.softmax(sg, axis=-1), g, axes=[2,1]) # [t, 8d]\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cos_sim (x):\n",
    "    p = x[0] # [t, 2d]\n",
    "    q = x[1] # [j, 2d]\n",
    "    s = dot([p, K.permute_dimensions(q, (0,2,1))], axes=(2,1), normalize=True) # [t, j] cosine simlilarity\n",
    "    max_sim = K.max(s, axis=-1, keepdims=True) # [t, 1]\n",
    "    return max_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def single_model():\n",
    "    p = Input(shape=(maxlen_p,))\n",
    "    q = Input(shape=(maxlen_q,))\n",
    "    p_fea = Input(shape=(maxlen_p, features)) # passage word feature\n",
    "    q_fea = Input(shape=(maxlen_q, features)) # query word feature\n",
    "    \n",
    "    # Embedding layer\n",
    "    embed = Embedding(nb_words+1, embed_size, weights=[embedding_matrix], trainable=False)\n",
    "    p_emb = embed(p) # word embedding\n",
    "    qe = embed(q)\n",
    "    p_cos = Lambda(cos_sim)([p_emb, qe])\n",
    "    q_cos = Lambda(cos_sim)([qe, p_emb])\n",
    "    p_emb = SpatialDropout1D(0.2)(p_emb)\n",
    "    qe = SpatialDropout1D(0.2)(qe)\n",
    "    pf = Concatenate()([p_emb, p_fea, p_cos]) # passage feature vec = word embedding + (exact match + option match) + cos-sim\n",
    "    qe = Concatenate()([qe, q_fea, q_cos]) \n",
    "    \n",
    "    # Contextual embedding layer\n",
    "    h = Bidirectional(CuDNNLSTM(num_rnn_units, return_sequences=True))(pf) # [t, 2d]\n",
    "    u = Bidirectional(CuDNNLSTM(num_rnn_units, return_sequences=True))(qe) # [j,2d]\n",
    "    \n",
    "    # Attention flow layer\n",
    "    g = Lambda(attention_flow)([h, u]) # [t, 8d]\n",
    "    \n",
    "    # Modelling layer\n",
    "    m, hf, cf, hb, cb = Bidirectional(CuDNNLSTM(num_rnn_units, return_sequences=True, return_state=True))(g) # [t, 2d], d, d, d, d\n",
    "    #m = Bidirectional(CuDNNLSTM(num_rnn_units, return_sequences=True))(m) # [t, 2d]\n",
    "\n",
    "    # Output layer\n",
    "    conc = Concatenate()([g, m]) # [t, 10d]\n",
    "    gmp = GlobalMaxPooling1D()(conc) # [10d]\n",
    "    gap = GlobalAveragePooling1D()(conc) # [10d]\n",
    "    y = Concatenate()([gmp, gap, hf, hb]) # [22d]\n",
    "\n",
    "    x = BatchNormalization()(y)\n",
    "    x = Dense(num_hidden_units, activation='relu')(x)\n",
    "    x = Dropout(drop_prob)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    #x = Dense(num_hidden_units, activation='relu')(x)\n",
    "    #x = Dropout(drop_prob)(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=[p, q, p_fea, q_fea], outputs=x)\n",
    "    #print (model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected int32, got 0.0 of type 'float' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-cef3740a1233>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0madam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclipnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msingle_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'binary_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-63-bd255477321a>\u001b[0m in \u001b[0;36msingle_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# Attention flow layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_flow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# [t, 8d]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m# Modelling layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\deep2\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    458\u001b[0m             \u001b[1;31m# Actually call the layer,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m             \u001b[1;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\deep2\\lib\\site-packages\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask)\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhas_arg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mask'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m             \u001b[0marguments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mask'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-61-f81910bafb0a>\u001b[0m in \u001b[0;36mattention_flow\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp2q\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_p2q\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_q2p\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# [t, 8d]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# self-attention\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_dimensions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# [t, t]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# [t, 8d]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\deep2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36msqrt\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1471\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1472\u001b[0m     \"\"\"\n\u001b[1;32m-> 1473\u001b[1;33m     \u001b[0mzero\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1474\u001b[0m     \u001b[0minf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1475\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_by_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzero\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\deep2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_to_tensor\u001b[1;34m(x, dtype)\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m     \"\"\"\n\u001b[1;32m--> 305\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\deep2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[0;32m   1012\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m       as_ref=False)\n\u001b[0m\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\deep2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1104\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\deep2\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    233\u001b[0m                                          as_ref=False):\n\u001b[0;32m    234\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\deep2\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[0;32m    212\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m    213\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[1;32m--> 214\u001b[1;33m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[0;32m    215\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\deep2\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    430\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m       \u001b[0m_AssertCompatible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m       \u001b[1;31m# check to them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\deep2\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36m_AssertCompatible\u001b[1;34m(values, dtype)\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m       raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n\u001b[1;32m--> 343\u001b[1;33m                       (dtype.name, repr(mismatch), type(mismatch).__name__))\n\u001b[0m\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected int32, got 0.0 of type 'float' instead."
     ]
    }
   ],
   "source": [
    "adam = optimizers.Adam(lr=0.001, clipnorm=max_norm)\n",
    "model = single_model()\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['binary_accuracy'])\n",
    "    \n",
    "# train the model\n",
    "cp = ModelCheckpoint(filepath='./model/my4.h5', monitor='val_binary_accuracy', save_best_only=True, save_weights_only=True)\n",
    "es = EarlyStopping(patience=2, monitor='val_binary_accuracy')\n",
    "rp = ReduceLROnPlateau(patience = 1, monitor='val_loss')\n",
    "hist = model.fit(\n",
    "    [train_p, train_q, train_feature_p, train_feature_q], \n",
    "    train_l,\n",
    "    batch_size = batch_size,\n",
    "    epochs = 12,\n",
    "    shuffle = True,\n",
    "    validation_data = ([valid_p, valid_q, valid_feature_p, valid_feature_q], valid_l), \n",
    "    callbacks=[es, rp, cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [0.4272381802664863, 0.41308247687021893, 0.40422273644341361, 0.39830680662790935, 0.40596646783616808, 0.40318613475693599, 0.40440964979065791, 0.4044959357102712, 0.40511343022452462, 0.40427665614022151], 'val_binary_accuracy': [0.80021111113230392, 0.80976666668785946, 0.81505555554495912, 0.81845555559794103, 0.81897777774598868, 0.82181111110051475, 0.82193333329094775, 0.82208888889948528, 0.8218333333333333, 0.82194444445504078], 'loss': [0.48342471433512368, 0.4207474135977427, 0.39844670414924621, 0.38033337049738564, 0.36438371469306946, 0.33773065061823526, 0.3312468145942688, 0.3302969782218933, 0.3303135731983185, 0.33011091243298846], 'binary_accuracy': [0.76240133333206173, 0.80517333333841956, 0.81806666666793826, 0.82823066666920975, 0.83637733333333331, 0.85016133333333332, 0.85345599999999999, 0.85343733333460492, 0.85372133333587652, 0.85411599999872845], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 1.0000001e-05, 1.0000001e-06, 1.0000001e-07, 1.0000001e-08]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x133667b86a0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (hist.history)\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(1)\n",
    "plt.plot (hist.history['binary_accuracy'])\n",
    "plt.plot (hist.history['val_binary_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = model.predict([test_p, test_q, test_feature_p, test_feature_q], batch_size=batch_size*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000,)\n"
     ]
    }
   ],
   "source": [
    "test_pred = np.squeeze(test_pred)\n",
    "print(test_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the array into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame({'id':test['id'], 'passage':test['passage'], 'query':test['query'], 'option':test['option'], 'label':test_pred})\n",
    "res.to_csv('./result/test15_long.csv', index=False, encoding='utf-8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
