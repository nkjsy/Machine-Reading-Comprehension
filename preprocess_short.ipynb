{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "from pyhanlp import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = './data/ai_challenger_oqmrc_trainingset.json' # train set\n",
    "valid_path = './data/ai_challenger_oqmrc_validationset.json' # validation set\n",
    "test_path = './data/ai_challenger_oqmrc_testa.json' # test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load my own dictionary from sougou to help jieba cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jieba.load_userdict('./my_dict.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.read_json(train_path, orient='records', encoding='utf-8', lines=True)\n",
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alternatives</th>\n",
       "      <th>answer</th>\n",
       "      <th>passage</th>\n",
       "      <th>query</th>\n",
       "      <th>query_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>有|没有|无法确定</td>\n",
       "      <td>有</td>\n",
       "      <td>动漫好看的H：爱的魔法，KEY的作品，喧嚣学院，草莓100%，双恋，爱丽丝学园，灼眼的夏娜，...</td>\n",
       "      <td>有没有好看的h</td>\n",
       "      <td>250001</td>\n",
       "      <td>http://iask.sina.com.cn/key/5a18d46b84aedabb5c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>能|不能|无法确定</td>\n",
       "      <td>能</td>\n",
       "      <td>醋泡鸡蛋确实具有一定美白嫩化肌肤、提高皮肤亮度、祛斑的效果，因为白醋中含有的醋酸可以加速表皮...</td>\n",
       "      <td>醋泡鸡蛋真能去斑吗</td>\n",
       "      <td>250002</td>\n",
       "      <td>http://www.120ask.com/question/65970789.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>听不懂|听得懂|无法确定</td>\n",
       "      <td>听不懂</td>\n",
       "      <td>人有人言，兽有兽语。动物是不会听懂人说话的</td>\n",
       "      <td>老鼠听得懂人话吗</td>\n",
       "      <td>250003</td>\n",
       "      <td>http://wenwen.sogou.com/z/q166740184.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>无法确定|大|不大</td>\n",
       "      <td>无法确定</td>\n",
       "      <td>1.前期投资约5-10万元设备投资：柜台、门面装修、电脑及简单家具，一次性投入约2万元。2....</td>\n",
       "      <td>开洗车店投资大吗</td>\n",
       "      <td>250004</td>\n",
       "      <td>http://wenwen.sogou.com/z/q705319471.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>会|不会|无法确定</td>\n",
       "      <td>会</td>\n",
       "      <td>性接触没有保护措施，是有感染的几率的，艾滋病没有特异性的症状。</td>\n",
       "      <td>类似性行为会不会感染艾滋病</td>\n",
       "      <td>250005</td>\n",
       "      <td>http://www.169kang.com/question/166710467.html</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alternatives answer                                            passage  \\\n",
       "0     有|没有|无法确定      有  动漫好看的H：爱的魔法，KEY的作品，喧嚣学院，草莓100%，双恋，爱丽丝学园，灼眼的夏娜，...   \n",
       "1     能|不能|无法确定      能  醋泡鸡蛋确实具有一定美白嫩化肌肤、提高皮肤亮度、祛斑的效果，因为白醋中含有的醋酸可以加速表皮...   \n",
       "2  听不懂|听得懂|无法确定    听不懂                              人有人言，兽有兽语。动物是不会听懂人说话的   \n",
       "3     无法确定|大|不大   无法确定  1.前期投资约5-10万元设备投资：柜台、门面装修、电脑及简单家具，一次性投入约2万元。2....   \n",
       "4     会|不会|无法确定      会                    性接触没有保护措施，是有感染的几率的，艾滋病没有特异性的症状。   \n",
       "\n",
       "           query  query_id                                                url  \n",
       "0        有没有好看的h    250001  http://iask.sina.com.cn/key/5a18d46b84aedabb5c...  \n",
       "1      醋泡鸡蛋真能去斑吗    250002        http://www.120ask.com/question/65970789.htm  \n",
       "2       老鼠听得懂人话吗    250003           http://wenwen.sogou.com/z/q166740184.htm  \n",
       "3       开洗车店投资大吗    250004           http://wenwen.sogou.com/z/q705319471.htm  \n",
       "4  类似性行为会不会感染艾滋病    250005     http://www.169kang.com/question/166710467.html  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_set = pd.read_json(valid_path, orient='records', encoding='utf-8', lines=True)\n",
    "valid_set.head()\n",
    "#valid_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alternatives</th>\n",
       "      <th>passage</th>\n",
       "      <th>query</th>\n",
       "      <th>query_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>能|不能|无法确定</td>\n",
       "      <td>武威公交一体化纪实 10家运输公司中标经营包括凉州区、古浪、民勤、天祝在内的城乡公交线路。经...</td>\n",
       "      <td>武威的公交卡古浪能不能用</td>\n",
       "      <td>280001</td>\n",
       "      <td>http://gsrb.gansudaily.com.cn/system/2009/08/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>能|不能|无法确定</td>\n",
       "      <td>现在这个社会什么买不到，只要你有钱是不是 欢迎光临【深圳平安安防】无线的有线的都有呢，看你喜...</td>\n",
       "      <td>能买到无线偷拍器吗</td>\n",
       "      <td>280002</td>\n",
       "      <td>http://wenwen.sogou.com/z/q701006723.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>是真的|不是真的|无法确定</td>\n",
       "      <td>请问朋友们网上中安信业代款是真的吗？ 【百度反诈骗联盟团队】特别提醒：网上发布的所有只凭身份...</td>\n",
       "      <td>中安信业减免还款是真实的吗</td>\n",
       "      <td>280003</td>\n",
       "      <td>http://wenwen.sogou.com/z/q763575352.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>能|不能|无法确定</td>\n",
       "      <td>对于这些的话也可以咨询一下你的直属上司或者是领导，他们专业的意见也都是可以的。</td>\n",
       "      <td>petct医保报销吗</td>\n",
       "      <td>280004</td>\n",
       "      <td>http://www.mama.cn/ask/q13547252-p1.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>慢热|不慢热|无法确定</td>\n",
       "      <td>在巨蟹座当中，慢热型的性格，更是让她们的爱心与细腻，更好的发挥到极致。</td>\n",
       "      <td>巨蟹座慢热么</td>\n",
       "      <td>280005</td>\n",
       "      <td>http://www.d1xz.net/astro/Cancer/art117849.aspx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alternatives                                            passage  \\\n",
       "0      能|不能|无法确定  武威公交一体化纪实 10家运输公司中标经营包括凉州区、古浪、民勤、天祝在内的城乡公交线路。经...   \n",
       "1      能|不能|无法确定  现在这个社会什么买不到，只要你有钱是不是 欢迎光临【深圳平安安防】无线的有线的都有呢，看你喜...   \n",
       "2  是真的|不是真的|无法确定  请问朋友们网上中安信业代款是真的吗？ 【百度反诈骗联盟团队】特别提醒：网上发布的所有只凭身份...   \n",
       "3      能|不能|无法确定            对于这些的话也可以咨询一下你的直属上司或者是领导，他们专业的意见也都是可以的。   \n",
       "4    慢热|不慢热|无法确定                在巨蟹座当中，慢热型的性格，更是让她们的爱心与细腻，更好的发挥到极致。   \n",
       "\n",
       "           query  query_id                                                url  \n",
       "0   武威的公交卡古浪能不能用    280001  http://gsrb.gansudaily.com.cn/system/2009/08/2...  \n",
       "1      能买到无线偷拍器吗    280002           http://wenwen.sogou.com/z/q701006723.htm  \n",
       "2  中安信业减免还款是真实的吗    280003           http://wenwen.sogou.com/z/q763575352.htm  \n",
       "3     petct医保报销吗    280004           http://www.mama.cn/ask/q13547252-p1.html  \n",
       "4         巨蟹座慢热么    280005    http://www.d1xz.net/astro/Cancer/art117849.aspx  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = pd.read_json(test_path, orient='records', encoding='utf-8', lines=True)\n",
    "print (test_set.shape)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['甲减', '能', '自', '愈', '吗']\n"
     ]
    }
   ],
   "source": [
    "def nlp_seg(text):\n",
    "    NLPTokenizer = JClass(\"com.hankcs.hanlp.tokenizer.NLPTokenizer\")\n",
    "    seg = NLPTokenizer.segment(text)\n",
    "    l = [i.word for i in seg]\n",
    "    return l\n",
    "print (nlp_seg('甲减能自愈吗'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocess function to clean a text \n",
    "cut words, remove punctuation, lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text, aug=False):\n",
    "    jieba.suggest_freq(('不', '会'), tune=True)\n",
    "    jieba.suggest_freq(('不', '能'), tune=True)\n",
    "    jieba.suggest_freq(('不', '行'), tune=True)\n",
    "    jieba.suggest_freq(('不', '好'), tune=True)\n",
    "    jieba.suggest_freq(('不', '要'), tune=True)\n",
    "    jieba.suggest_freq(('不', '是'), tune=True)\n",
    "    jieba.suggest_freq(('不'), tune=True)\n",
    "    jieba.suggest_freq('无法确定', tune=True)\n",
    "    sent = jieba.lcut(text, HMM=False)\n",
    "\n",
    "    for i in range(len(sent)):\n",
    "        if sent[i] in \"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）：【】]+\":\n",
    "            sent[i] = ' '\n",
    "        elif aug and random.random()<0.1: # data augmentation\n",
    "            sent[i] = ' '\n",
    "        else:\n",
    "            sent[i].lower()\n",
    "    sent = ' '.join(sent)\n",
    "    return sent\n",
    "\n",
    "#print (preprocess('塞庚啶好还是扑尔敏好', 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# concatenate query and alternatives\n",
    "def query_alt(query, alternatives, a):\n",
    "    '''\n",
    "    query: line['query'] from original dataframe\n",
    "    alternatives: line['alternatives'] from original dataframe\n",
    "    a: current option in alternatives to be merged with query\n",
    "    \n",
    "    return: query and current option a concatenated (preprocessed)\n",
    "    '''\n",
    "    \n",
    "    query = query.strip()\n",
    "    if query[-1] == \"吗\" or query[-1] == \"么\" or query[-1] == \"嘛\" or query[-1] == \"不\": \n",
    "        query = query[:-1]\n",
    "        match = None\n",
    "        o = alternatives.split('|')\n",
    "        o = [m.strip() for m in o]\n",
    "        if '无法确认' in o:\n",
    "            o.remove('无法确认')\n",
    "        if '无法确定' in o:\n",
    "            o.remove('无法确定') \n",
    "        if o[0] in o[1]:\n",
    "            long = o[1]\n",
    "            short = o[0]\n",
    "        else:\n",
    "            long = o[0]\n",
    "            short = o[1]\n",
    "        if long in query:\n",
    "            match = long\n",
    "        else:\n",
    "            if short in query:\n",
    "                match = short\n",
    "            elif (short == '能') and ('可以' in query):\n",
    "                match = '可以'\n",
    "            elif (short == '可以') and ('能' in query):\n",
    "                match = '能'\n",
    "            elif (short == '可以') and ('会' in query):\n",
    "                match = '会'\n",
    "            elif (short == '会') and ('可以' in query):\n",
    "                match = '可以'\n",
    "            elif (short == '会') and ('能' in query):\n",
    "                match = '能'\n",
    "            elif (short == '能') and ('会' in query):\n",
    "                match = '会'\n",
    "\n",
    "        if match:\n",
    "            query = query.replace(match, a)\n",
    "        else:\n",
    "            query = a + query\n",
    "            \n",
    "        merged = preprocess(query, alternatives)\n",
    "        return merged\n",
    "            \n",
    "    else: # 问题里正反两个词都要替换\n",
    "        match = alternatives.split('|')\n",
    "        match = [m.strip() for m in match]\n",
    "        if '无法确认' in match:\n",
    "            match.remove('无法确认')\n",
    "        if '无法确定' in match:\n",
    "            match.remove('无法确定') \n",
    "        if match[0] in query and match[1] in query: # 两个词都出现了\n",
    "            if match[0] + match[1] in query: # 有没有，会不会\n",
    "                query = query.replace(match[0] + match[1], a)\n",
    "            elif match[1] + match[0] in query:\n",
    "                query = query.replace(match[1] + match[0], a)\n",
    "            else: # A好还是B好\n",
    "                if a == match[0]:\n",
    "                    query = query.replace(match[1], ' ')\n",
    "                elif a == match[1]:\n",
    "                    query = query.replace(match[0], ' ')\n",
    "                else: # 无法确定\n",
    "                    query = query.replace(match[0], ' ')\n",
    "                    query = query.replace(match[1], a)\n",
    "        else: # 两个词没完整出现\n",
    "            if '能否' in query:\n",
    "                query = query.replace('能否', a)\n",
    "            elif '是否' in query:\n",
    "                query = query.replace('是否', a)\n",
    "            elif '可否' in query:\n",
    "                query = query.replace('可否', a)\n",
    "            \n",
    "        merged = preprocess(query, alternatives)\n",
    "        return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>Some records have wrong data 三个选项中有重复\n",
    "train: 25635, 59325, 89727, 120004, 143044, 154519, 219549, 249465, 249485\n",
    "\n",
    "valid: 22156, 23656"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alternatives                        浴网好|浴板好|无法确定\n",
      "answer                                       浴网好\n",
      "passage             婴儿浴盆的选择是要看宝宝的情况的，一般来说浴网比较好用。\n",
      "query                              婴儿浴盆带浴网好还是浴板好\n",
      "query_id                                  154520\n",
      "url             http://www.mama.cn/z/wiki/56092/\n",
      "Name: 154519, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print (train_set.iloc[154519])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### write into the tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                       | 0/250000 [00:00<?, ?it/s]\n",
      "  0%|                                                                             | 79/250000 [00:00<05:19, 782.96it/s]\n",
      "  0%|                                                                            | 172/250000 [00:00<05:16, 790.41it/s]\n",
      "  0%|                                                                            | 252/250000 [00:00<05:16, 789.95it/s]\n",
      "  0%|                                                                            | 337/250000 [00:00<05:09, 805.96it/s]\n",
      "  0%|▏                                                                           | 432/250000 [00:00<05:07, 811.15it/s]\n",
      "  0%|▏                                                                           | 516/250000 [00:00<05:06, 813.44it/s]\n",
      "  0%|▏                                                                           | 611/250000 [00:00<05:04, 818.92it/s]\n",
      "  0%|▏                                                                           | 696/250000 [00:00<05:02, 824.55it/s]\n",
      "  0%|▏                                                                           | 783/250000 [00:00<04:57, 837.09it/s]\n",
      "  0%|▎                                                                           | 871/250000 [00:01<04:53, 849.30it/s]\n",
      "  0%|▎                                                                           | 971/250000 [00:01<04:51, 855.53it/s]\n",
      "  0%|▎                                                                          | 1056/250000 [00:01<04:58, 833.12it/s]\n",
      "  0%|▎                                                                          | 1150/250000 [00:01<04:57, 837.58it/s]\n",
      "  0%|▎                                                                          | 1248/250000 [00:01<04:54, 843.51it/s]\n",
      "  1%|▍                                                                          | 1337/250000 [00:01<04:53, 848.65it/s]\n",
      "  1%|▍                                                                          | 1423/250000 [00:01<05:05, 814.95it/s]\n",
      "  1%|▍                                                                          | 1509/250000 [00:01<05:01, 823.15it/s]\n",
      "  1%|▍                                                                          | 1608/250000 [00:01<04:58, 833.31it/s]\n",
      "  1%|▌                                                                          | 1692/250000 [00:02<04:58, 833.03it/s]\n",
      "  1%|▌                                                                          | 1776/250000 [00:02<04:57, 834.06it/s]\n",
      "  1%|▌                                                                          | 1860/250000 [00:02<05:02, 819.62it/s]\n",
      "  1%|▌                                                                          | 1954/250000 [00:02<04:59, 828.75it/s]\n",
      "  1%|▌                                                                          | 2037/250000 [00:02<05:05, 812.52it/s]\n",
      "  1%|▋                                                                          | 2123/250000 [00:02<05:09, 802.04it/s]\n",
      "  1%|▋                                                                          | 2208/250000 [00:02<05:04, 814.47it/s]\n",
      "  1%|▋                                                                          | 2290/250000 [00:02<05:13, 791.21it/s]\n",
      "  1%|▋                                                                          | 2370/250000 [00:02<05:15, 784.32it/s]\n",
      "  1%|▋                                                                          | 2455/250000 [00:02<05:11, 793.71it/s]\n",
      "  1%|▊                                                                          | 2535/250000 [00:03<05:16, 782.41it/s]\n",
      "  1%|▊                                                                          | 2628/250000 [00:03<05:08, 801.93it/s]\n",
      "  1%|▊                                                                          | 2711/250000 [00:03<05:05, 808.75it/s]\n",
      "  1%|▊                                                                          | 2798/250000 [00:03<05:00, 822.87it/s]\n",
      "  1%|▊                                                                          | 2895/250000 [00:03<04:57, 831.92it/s]\n",
      "  1%|▉                                                                          | 2982/250000 [00:03<04:54, 837.58it/s]\n",
      "  1%|▉                                                                          | 3066/250000 [00:03<04:55, 836.40it/s]\n",
      "  1%|▉                                                                          | 3150/250000 [00:03<04:55, 836.47it/s]\n",
      "  1%|▉                                                                          | 3234/250000 [00:03<04:55, 835.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 250000/250000 [06:13<00:00, 669.30it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('./data/train1.tsv', 'w', encoding='utf-8') as fw:\n",
    "    fw.write('id' + '\\t' + 'passage' + '\\t' + 'a0' + '\\t' + 'a1' + '\\t' + 'a2' + '\\t' + 'answer' + '\\n')\n",
    "    for i in tqdm(range(train_set.shape[0])):\n",
    "        line = train_set.iloc[i]\n",
    "        p = preprocess(line['passage'])\n",
    "        q = line['query']\n",
    "        fw.write(str(line['query_id'])+ '\\t'+ p)\n",
    "        l = line['alternatives'].split('|')\n",
    "        random.shuffle(l)\n",
    "        ind = 0\n",
    "        for i, a in enumerate(l):\n",
    "            a = a.strip()\n",
    "            m = query_alt(query=q, alternatives=line['alternatives'], a=a)\n",
    "            if a == line['answer'].strip():\n",
    "                ind = i\n",
    "            fw.write('\\t'+ m)\n",
    "        fw.write('\\t'+ str(ind)+ '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 30000/30000 [00:48<00:00, 622.06it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('./data/valid1.tsv', 'w', encoding='utf-8') as fw:\n",
    "    fw.write('id' + '\\t' + 'passage' + '\\t' + 'a0' + '\\t' + 'a1' + '\\t' + 'a2' + '\\t' + 'answer' + '\\n')\n",
    "    for i in tqdm(range(valid_set.shape[0])):\n",
    "        line = valid_set.iloc[i]\n",
    "        p = preprocess(line['passage'])\n",
    "        q = line['query']\n",
    "        fw.write(str(line['query_id'])+ '\\t'+ p)\n",
    "        l = line['alternatives'].split('|')\n",
    "        random.shuffle(l)\n",
    "        ind = 0\n",
    "        for i, a in enumerate(l):\n",
    "            a = a.strip()\n",
    "            m = query_alt(query=q, alternatives=line['alternatives'], a=a)\n",
    "            if a == line['answer'].strip():\n",
    "                ind = i\n",
    "            fw.write('\\t'+ m)\n",
    "        fw.write('\\t'+ str(ind)+ '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:16<00:00, 598.02it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('./data/test1.tsv', 'w', encoding='utf-8') as fw:\n",
    "    fw.write('id' + '\\t' + 'passage' + '\\t' + 'a0' + '\\t' + 'a1' + '\\t' + 'a2' + '\\n')\n",
    "    for i in tqdm(range(test_set.shape[0])):\n",
    "        line = test_set.iloc[i]\n",
    "        p = preprocess(line['passage'])\n",
    "        q = line['query']\n",
    "        fw.write(str(line['query_id'])+ '\\t'+ p)\n",
    "        l = line['alternatives'].split('|')\n",
    "        for i, a in enumerate(l):\n",
    "            a = a.strip()\n",
    "            m = query_alt(query=q, alternatives=line['alternatives'], a=a)\n",
    "            fw.write('\\t'+ m)\n",
    "        fw.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <font color=red>测试集test A 有两条有误！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "289730只有一个选项，无法确定。\n",
    "\n",
    "289334只有两个选项，不能or无法确定。选不能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part II: Add features for words in passage\n",
    "Add Exact match, soft align and Pos tag features. Refer to SAN model: https://arxiv.org/abs/1712.03556\n",
    "\n",
    "Delete soft-align and pos tag. Add option exact match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen_p = 150\n",
    "maxlen_q = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = './data/train1.tsv' # train set\n",
    "valid_path = './data/valid1.tsv' # validation set\n",
    "test_path = './data/test1.tsv' # test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_path, sep='\\t', header=0)\n",
    "valid = pd.read_csv(valid_path, sep='\\t', header=0)\n",
    "test = pd.read_csv(test_path, sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 6) (30000, 6) (10000, 5)\n"
     ]
    }
   ],
   "source": [
    "print (train.shape, valid.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 750000/750000 [32:30<00:00, 384.44it/s] 88%|███████████████████████████████████████████████████████████████▉         | 656584/750000 [31:47<04:31, 344.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000, 150, 2) (750000, 15, 2)\n"
     ]
    }
   ],
   "source": [
    "pl = []\n",
    "ql = []\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    line = train.iloc[i]\n",
    "    q_words = line['query'].split()\n",
    "    p_words = line['passage'].split()\n",
    "    option = line['option']\n",
    "    \n",
    "    if len(p_words) > maxlen_p: # truncate pre\n",
    "        lt = len(p_words) - maxlen_p\n",
    "        p_words = p_words[lt:]\n",
    "    if len(q_words) > maxlen_q: # truncate post\n",
    "        q_words = q_words[:maxlen_q]\n",
    "\n",
    "    pfea = []\n",
    "    for w in p_words:\n",
    "        # exact match\n",
    "        if w in q_words:\n",
    "            em = 1\n",
    "        else:\n",
    "            em = 0\n",
    "        # option match\n",
    "        if w == option:\n",
    "            om = 1\n",
    "        else:\n",
    "            om = 0\n",
    "        pfea.append([em, om])\n",
    "        \n",
    "    qfea = []\n",
    "    for w in q_words:\n",
    "        # exact match\n",
    "        if w in p_words:\n",
    "            em = 1\n",
    "        else:\n",
    "            em = 0\n",
    "        # option match\n",
    "        if w == option:\n",
    "            om = 1\n",
    "        else:\n",
    "            om = 0\n",
    "        qfea.append([em, om])\n",
    "        \n",
    "    while len(pfea) < maxlen_p: # pad with 0 pre\n",
    "        pfea.insert(0, [0] * 2)\n",
    "    pl.append(pfea)\n",
    "    while len(qfea) < maxlen_q: # pad with 0 post\n",
    "        qfea.append([0] * 2)\n",
    "    ql.append(qfea)\n",
    "\n",
    "pl = np.asarray(pl)\n",
    "ql = np.asarray(ql)\n",
    "np.save('./data/train_fea_p', pl)\n",
    "np.save('./data/train_fea_q', ql)\n",
    "print (np.shape(pl), np.shape(ql))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 90000/90000 [00:35<00:00, 2535.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90000, 150, 2) (90000, 15, 2)\n"
     ]
    }
   ],
   "source": [
    "pl = []\n",
    "ql = []\n",
    "for i in tqdm(range(valid.shape[0])):\n",
    "    line = valid.iloc[i]\n",
    "    q_words = line['query'].split()\n",
    "    p_words = line['passage'].split()\n",
    "    option = line['option']\n",
    "    \n",
    "    if len(p_words) > maxlen_p: # truncate pre\n",
    "        lt = len(p_words) - maxlen_p\n",
    "        p_words = p_words[lt:]\n",
    "    if len(q_words) > maxlen_q: # truncate post\n",
    "        q_words = q_words[:maxlen_q]\n",
    "\n",
    "    pfea = []\n",
    "    for w in p_words:\n",
    "        # exact match\n",
    "        if w in q_words:\n",
    "            em = 1\n",
    "        else:\n",
    "            em = 0\n",
    "        # option match\n",
    "        if w == option:\n",
    "            om = 1\n",
    "        else:\n",
    "            om = 0\n",
    "        pfea.append([em, om])\n",
    "        \n",
    "    qfea = []\n",
    "    for w in q_words:\n",
    "        # exact match\n",
    "        if w in p_words:\n",
    "            em = 1\n",
    "        else:\n",
    "            em = 0\n",
    "        # option match\n",
    "        if w == option:\n",
    "            om = 1\n",
    "        else:\n",
    "            om = 0\n",
    "        qfea.append([em, om])\n",
    "        \n",
    "    while len(pfea) < maxlen_p: # pad with 0 pre\n",
    "        pfea.insert(0, [0] * 2)\n",
    "    pl.append(pfea)\n",
    "    while len(qfea) < maxlen_q: # pad with 0 post\n",
    "        qfea.append([0] * 2)\n",
    "    ql.append(qfea)\n",
    "\n",
    "pl = np.asarray(pl)\n",
    "ql = np.asarray(ql)\n",
    "np.save('./data/valid_fea_p', pl)\n",
    "np.save('./data/valid_fea_q', ql)\n",
    "print (np.shape(pl), np.shape(ql))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 30000/30000 [00:09<00:00, 3117.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 150, 2) (30000, 15, 2)\n"
     ]
    }
   ],
   "source": [
    "pl = []\n",
    "ql = []\n",
    "for i in tqdm(range(test.shape[0])):\n",
    "    line = test.iloc[i]\n",
    "    q_words = line['query'].split()\n",
    "    p_words = line['passage'].split()\n",
    "    option = line['option']\n",
    "    \n",
    "    if len(p_words) > maxlen_p: # truncate pre\n",
    "        lt = len(p_words) - maxlen_p\n",
    "        p_words = p_words[lt:]\n",
    "    if len(q_words) > maxlen_q: # truncate post\n",
    "        q_words = q_words[:maxlen_q]\n",
    "\n",
    "    pfea = []\n",
    "    for w in p_words:\n",
    "        # exact match\n",
    "        if w in q_words:\n",
    "            em = 1\n",
    "        else:\n",
    "            em = 0\n",
    "        # option match\n",
    "        if w == option:\n",
    "            om = 1\n",
    "        else:\n",
    "            om = 0\n",
    "        pfea.append([em, om])\n",
    "        \n",
    "    qfea = []\n",
    "    for w in q_words:\n",
    "        # exact match\n",
    "        if w in p_words:\n",
    "            em = 1\n",
    "        else:\n",
    "            em = 0\n",
    "        # option match\n",
    "        if w == option:\n",
    "            om = 1\n",
    "        else:\n",
    "            om = 0\n",
    "        qfea.append([em, om])\n",
    "        \n",
    "    while len(pfea) < maxlen_p: # pad with 0 pre\n",
    "        pfea.insert(0, [0] * 2)\n",
    "    pl.append(pfea)\n",
    "    while len(qfea) < maxlen_q: # pad with 0 post\n",
    "        qfea.append([0] * 2)\n",
    "    ql.append(qfea)\n",
    "\n",
    "pl = np.asarray(pl)\n",
    "ql = np.asarray(ql)\n",
    "np.save('./data/test_fea_p', pl)\n",
    "np.save('./data/test_fea_q', ql)\n",
    "print (np.shape(pl), np.shape(ql))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
