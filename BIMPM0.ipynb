{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc, random, math, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, Embedding, Dropout, Activation, SpatialDropout1D, BatchNormalization, RepeatVector, Lambda\n",
    "from keras.layers.merge import concatenate, multiply, dot, Concatenate\n",
    "from keras.layers import LSTM, GRU, CuDNNLSTM, CuDNNGRU\n",
    "from keras.layers import Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D, TimeDistributed\n",
    "from keras.models import Model, Sequential\n",
    "from keras import optimizers, layers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 120000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen_p = 150 # max number of words in a context to use\n",
    "maxlen_q = 10 # max number of words in a question to use\n",
    "batch_size = 128\n",
    "num_rnn_units = 32\n",
    "num_hidden_units = 200\n",
    "drop_prob = 0.5\n",
    "max_norm = 5.0\n",
    "mp = 3\n",
    "features = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './data/train.tsv' # train set\n",
    "valid_path = './data/valid.tsv' # validation set\n",
    "test_path = './data/test.tsv' # test set\n",
    "embed_file = './sgns.target.word-ngram.1-2.dynwin5.thr10.neg5.dim300.iter5' # 预训练词向量\n",
    "fasttext_file = './cc.zh.300.vec' # 预训练词向量\n",
    "train_feature_path = './data/train_fea.npy' # train passage word feature\n",
    "valid_feature_path = './data/valid_fea.npy' # validation passage word feature\n",
    "test_feature_path = './data/test_fea.npy' # test passage word feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000, 5) (90000, 5) (29997, 4)\n",
      "   id                                            passage  \\\n",
      "0   1  孩子 是 父母 的 一面镜子   由于 儿童 的 世界观 尚未 形成   他们   模仿 带...   \n",
      "1   1  孩子 是 父母 的 一面镜子   由于 儿童 的 世界观 尚未 形成     的 模仿 带有...   \n",
      "2   1  孩子 是 父母   一面镜子   由于 儿童 的 世界观 尚未 形成   他们 的   带有...   \n",
      "3   2  目前   中国 很多 地方   学生 火车票 磁条 都 已经 升级 了   在 磁条 里 已...   \n",
      "4   2  目前       地方   学生 火车票 磁条 都 已经   了   在 磁条 里 已经 写...   \n",
      "\n",
      "                     query option  label  \n",
      "0   无法确定 你 的 孩子 是 保姆 带 大 的   无法确定      1  \n",
      "1      是 你 的 孩子 是 保姆 带 大 的      是      0  \n",
      "2     不是 你 的 孩子 是 保姆 带 大 的     不是      0  \n",
      "3  不能 不是 一个 区间 刷 学生证 能 有 票     不能      1  \n",
      "4   能 不是 一个 区间 刷 学生证 能 有 票      能      0  \n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(train_path, sep='\\t', header=0)\n",
    "valid = pd.read_csv(valid_path, sep='\\t', header=0)\n",
    "test = pd.read_csv(test_path, sep='\\t', header=0)\n",
    "print (train.shape, valid.shape, test.shape)\n",
    "print (train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000, 150, 2) (90000, 150, 2) (29997, 150, 2)\n"
     ]
    }
   ],
   "source": [
    "train_feature = np.load(train_feature_path)\n",
    "valid_feature = np.load(valid_feature_path)\n",
    "test_feature = np.load(test_feature_path)\n",
    "print (train_feature.shape, valid_feature.shape, test_feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buld up the text input pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Fit the tokenizer on train, valid and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features, lower=True) \n",
    "\n",
    "tokenizer.fit_on_texts(pd.concat([train['passage'], train['query'], valid['passage'], valid['query'], test['passage'], test['query']], ignore_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1739994 175296\n"
     ]
    }
   ],
   "source": [
    "print (tokenizer.document_count, len(tokenizer.word_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text to seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_p = tokenizer.texts_to_sequences(train['passage'])\n",
    "tra_q = tokenizer.texts_to_sequences(train['query'])\n",
    "val_p = tokenizer.texts_to_sequences(valid['passage'])\n",
    "val_q = tokenizer.texts_to_sequences(valid['query'])\n",
    "te_p = tokenizer.texts_to_sequences(test['passage'])\n",
    "te_q = tokenizer.texts_to_sequences(test['query'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pad seq to maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p = pad_sequences(tra_p, maxlen=maxlen_p)\n",
    "train_q = pad_sequences(tra_q, maxlen=maxlen_q, padding='post', truncating='post')\n",
    "valid_p = pad_sequences(val_p, maxlen=maxlen_p)\n",
    "valid_q = pad_sequences(val_q, maxlen=maxlen_q, padding='post', truncating='post')\n",
    "test_p = pad_sequences(te_p, maxlen=maxlen_p)\n",
    "test_q = pad_sequences(te_q, maxlen=maxlen_q, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000, 150) (750000, 10) (90000, 150) (90000, 10) (29997, 150) (29997, 10)\n"
     ]
    }
   ],
   "source": [
    "print (train_p.shape, train_q.shape, valid_p.shape, valid_q.shape, test_p.shape, test_q.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_l = train['label']\n",
    "valid_l = valid['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000,) (90000,)\n"
     ]
    }
   ],
   "source": [
    "print (train_l.shape, valid_l.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the pretrained word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.strip().split()) for o in open(embed_file, encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.014820942, 0.26983637)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embs = np.hstack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "emb_mean,emb_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words+1, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i > max_features: break\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.asarray(embedding_matrix, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_index = dict(get_coefs(*o.strip().split()) for o in open(fasttext_file, encoding='utf-8'))\n",
    "all_ft = np.hstack(fasttext_index.values())\n",
    "ft_mean,ft_std = all_ft.mean(), all_ft.std()\n",
    "fasttext_matrix = np.random.normal(ft_mean, ft_std, (nb_words+1, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i > max_features: break\n",
    "    fasttext_vector = fasttext_index.get(word)\n",
    "    if fasttext_vector is not None: fasttext_matrix[i] = fasttext_vector\n",
    "fasttext_matrix = np.asarray(fasttext_matrix, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiPerspective(Layer):\n",
    "    \"\"\"Multi-perspective Matching Layer. (cannot do max attentive matching with keras)\n",
    "    # Arguments\n",
    "        mp_dim: single forward/backward multi-perspective dimention\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mp_dim, epsilon=1e-6, **kwargs):\n",
    "        self.mp_dim = mp_dim\n",
    "        self.epsilon = 1e-6\n",
    "        self.strategy = 3\n",
    "        super(MultiPerspective, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = input_shape[0]\n",
    "        embedding_size = input_shape[-1] / 2\n",
    "        embedding_size = int(embedding_size)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        # input_shape is bidirectional RNN input shape\n",
    "        # kernel shape (mp_dim * 2 * self.strategy, embedding_size)\n",
    "        self.kernel = self.add_weight((int(self.mp_dim),\n",
    "                                       int(embedding_size * 2 * self.strategy)),\n",
    "                                       name='kernel',\n",
    "                                       initializer='glorot_uniform',\n",
    "                                       trainable=True)\n",
    "        self.kernel_full_fw = self.kernel[:, :embedding_size]\n",
    "        self.kernel_full_bw = self.kernel[:, embedding_size: embedding_size * 2]\n",
    "        self.kernel_attentive_fw = self.kernel[:, embedding_size * 2: embedding_size * 3]\n",
    "        self.kernel_attentive_bw = self.kernel[:, embedding_size * 3: embedding_size * 4]\n",
    "        self.kernel_max_pool_fw = self.kernel[:, embedding_size * 4: embedding_size * 5]\n",
    "        self.kernel_max_pool_bw = self.kernel[:, embedding_size * 5:]\n",
    "        self.built = True\n",
    "        super(MultiPerspective, self).build(input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = input_shape[0]\n",
    "        return (input_shape[0], input_shape[1], self.mp_dim * 2 * self.strategy)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'mp_dim': self.mp_dim,\n",
    "                  'epsilon': self.epsilon}\n",
    "        base_config = super(MultiPerspective, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # h1, h2: bidirectional LSTM hidden states, include forward and backward states\n",
    "        #         (batch_size, timesteps, embedding_size * 2)\n",
    "        h1 = inputs[0]\n",
    "        h2 = inputs[1]\n",
    "        embedding_size = K.int_shape(h1)[-1] // 2\n",
    "        h1_fw = h1[:, :, :embedding_size]\n",
    "        h1_bw = h1[:, :, embedding_size:]\n",
    "        h2_fw = h2[:, :, :embedding_size]\n",
    "        h2_bw = h2[:, :, embedding_size:]\n",
    "\n",
    "        # 4 matching strategy\n",
    "        list_matching = []\n",
    "\n",
    "        # full matching ops\n",
    "        matching_fw = self._full_matching(h1_fw, h2_fw, self.kernel_full_fw)\n",
    "        matching_bw = self._full_matching(h1_bw, h2_bw, self.kernel_full_bw)\n",
    "        list_matching.extend([matching_fw, matching_bw])\n",
    "\n",
    "        # cosine matrix\n",
    "        cosine_matrix_fw = self._cosine_matrix(h1_fw, h2_fw)\n",
    "        cosine_matrix_bw = self._cosine_matrix(h1_bw, h2_bw)\n",
    "\n",
    "        # attentive matching ops\n",
    "        matching_fw = self._attentive_matching(\n",
    "            h1_fw, h2_fw, cosine_matrix_fw, self.kernel_attentive_fw)\n",
    "        matching_bw = self._attentive_matching(\n",
    "            h1_bw, h2_bw, cosine_matrix_bw, self.kernel_attentive_bw)\n",
    "        list_matching.extend([matching_fw, matching_bw])\n",
    "\n",
    "        # max pooling matching ops\n",
    "        matching_fw = self._max_pooling_matching(h1_fw, h2_fw, self.kernel_max_pool_fw)\n",
    "        matching_bw = self._max_pooling_matching(h1_bw, h2_bw, self.kernel_max_pool_bw)\n",
    "        list_matching.extend([matching_fw, matching_bw])\n",
    "\n",
    "        return K.concatenate(list_matching, axis=-1)\n",
    "\n",
    "    def _cosine_matrix(self, x1, x2):\n",
    "        \"\"\"Cosine similarity matrix.\n",
    "        Calculate the cosine similarities between each forward (or backward)\n",
    "        contextual embedding h_i_p and every forward (or backward)\n",
    "        contextual embeddings of the other sentence\n",
    "        # Arguments\n",
    "            x1: (batch_size, x1_timesteps, embedding_size)\n",
    "            x2: (batch_size, x2_timesteps, embedding_size)\n",
    "        # Output shape\n",
    "            (batch_size, x1_timesteps, x2_timesteps)\n",
    "        \"\"\"\n",
    "        s = dot([x1, K.permute_dimensions(x2, (0,2,1))], axes=(2,1), normalize=True) # [t, j]\n",
    "        return s\n",
    "\n",
    "    def _mean_attentive_vectors(self, x2, cosine_matrix):\n",
    "        \"\"\"Mean attentive vectors.\n",
    "        Calculate mean attentive vector for the entire sentence by weighted\n",
    "        summing all the contextual embeddings of the entire sentence\n",
    "        # Arguments\n",
    "            x2: sequence vectors, (batch_size, x2_timesteps, embedding_size)\n",
    "            cosine_matrix: cosine similarities matrix of x1 and x2,\n",
    "                           (batch_size, x1_timesteps, x2_timesteps)\n",
    "        # Output shape\n",
    "            (batch_size, x1_timesteps, embedding_size)\n",
    "        \"\"\"\n",
    "        attentive_vector = K.batch_dot(K.softmax(cosine_matrix, axis=-1), x2, axes=[2,1]) # [t, d]\n",
    "        return attentive_vector\n",
    "\n",
    "    def _time_distributed_multiply(self, x, w):\n",
    "        \"\"\"Element-wise multiply vector and weights.\n",
    "        # Arguments\n",
    "            x: sequence of hidden states, (batch_size, ?, embedding_size)\n",
    "            w: weights of one matching strategy of one direction,\n",
    "               (mp_dim, embedding_size)\n",
    "        # Output shape\n",
    "            (batch_size, ?, mp_dim, embedding_size)\n",
    "        \"\"\"\n",
    "        if K.ndim(x) == 3:\n",
    "            b = K.shape(x)[0]\n",
    "            t = K.shape(x)[1]\n",
    "            x = K.tile(K.expand_dims(x, axis=2), [1,1,self.mp_dim,1])\n",
    "            w = K.expand_dims(w, axis=0)\n",
    "            w = K.expand_dims(w, axis=0)\n",
    "            w = K.tile(w, [b,t,1,1])\n",
    "            m = multiply([x,w])\n",
    "        else:\n",
    "            b = K.shape(x)[0]\n",
    "            x = K.tile(K.expand_dims(x, axis=1), [1,self.mp_dim,1])\n",
    "            w = K.expand_dims(w, axis=0)\n",
    "            w = K.tile(w, [b,1,1])\n",
    "            m = multiply([x,w])\n",
    "        return m\n",
    "\n",
    "    def _full_matching(self, h1, h2, w):\n",
    "        \"\"\"Full matching operation.\n",
    "        # Arguments\n",
    "            h1: (batch_size, h1_timesteps, embedding_size)\n",
    "            h2: (batch_size, h2_timesteps, embedding_size)\n",
    "            w: weights of one direction, (mp_dim, embedding_size)\n",
    "        # Output shape\n",
    "            (batch_size, h1_timesteps, mp_dim)\n",
    "        \"\"\"\n",
    "        # h2 forward last step hidden vector, (batch_size, embedding_size)\n",
    "        h2_last_state = h2[:, -1, :]\n",
    "        # h1 * weights, (batch_size, h1_timesteps, mp_dim, embedding_size)\n",
    "        h1 = self._time_distributed_multiply(h1, w)\n",
    "        # h2_last_state * weights, (batch_size, mp_dim, embedding_size)\n",
    "        h2 = self._time_distributed_multiply(h2_last_state, w)\n",
    "        # reshape to (batch_size, 1, mp_dim, embedding_size)\n",
    "        h2 = K.expand_dims(h2, axis=1)\n",
    "        h2 = K.tile(h2, [1, K.shape(h1)[1], 1, 1])\n",
    "        # matching vector, (batch_size, h1_timesteps, mp_dim)\n",
    "        h1 = K.l2_normalize(h1, axis=-1)\n",
    "        h2 = K.l2_normalize(h2, axis=-1)\n",
    "        matching = K.sum(multiply([h1, h2]), axis=-1)\n",
    "        return matching\n",
    "\n",
    "    def _max_pooling_matching(self, h1, h2, w):\n",
    "        \"\"\"Max pooling matching operation.\n",
    "        # Arguments\n",
    "            h1: (batch_size, h1_timesteps, embedding_size)\n",
    "            h2: (batch_size, h2_timesteps, embedding_size)\n",
    "            w: weights of one direction, (mp_dim, embedding_size)\n",
    "        # Output shape\n",
    "            (batch_size, h1_timesteps, mp_dim)\n",
    "        \"\"\"\n",
    "        t1 = K.shape(h1)[1]\n",
    "        t2 = K.shape(h2)[1]\n",
    "        # h1 * weights, (batch_size, h1_timesteps, mp_dim, embedding_size)\n",
    "        h1 = self._time_distributed_multiply(h1, w)\n",
    "        # h2 * weights, (batch_size, h2_timesteps, mp_dim, embedding_size)\n",
    "        h2 = self._time_distributed_multiply(h2, w)\n",
    "        # reshape h1 to (batch_size, h1_timesteps, h2_timesteps, mp_dim, embedding_size)\n",
    "        h1 = K.expand_dims(h1, axis=2)\n",
    "        h1 = K.tile(h1, [1, 1, t2, 1, 1])\n",
    "        h1 = K.l2_normalize(h1, axis=-1)\n",
    "        # reshape v1 to (batch_size, h1_timesteps, h2_timesteps, mp_dim, embedding_size)\n",
    "        h2 = K.expand_dims(h2, axis=1)\n",
    "        h2 = K.tile(h2, [1, t1, 1, 1, 1])\n",
    "        h2 = K.l2_normalize(h2, axis=-1)\n",
    "        # cosine similarity, (batch_size, h1_timesteps, h2_timesteps, mp_dim)\n",
    "        cos = K.sum(multiply([h1, h2]), axis=-1)\n",
    "        # (batch_size, h1_timesteps, mp_dim)\n",
    "        matching = K.max(cos, axis=2)\n",
    "        return matching\n",
    "\n",
    "    def _attentive_matching(self, h1, h2, cosine_matrix, w):\n",
    "        \"\"\"Attentive matching operation.\n",
    "        # Arguments\n",
    "            h1: (batch_size, h1_timesteps, embedding_size)\n",
    "            h2: (batch_size, h2_timesteps, embedding_size)\n",
    "            cosine_matrix: weights of hidden state h2,\n",
    "                          (batch_size, h1_timesteps, h2_timesteps)\n",
    "            w: weights of one direction, (mp_dim, embedding_size)\n",
    "        # Output shape\n",
    "            (batch_size, h1_timesteps, mp_dim)\n",
    "        \"\"\"\n",
    "        # h1 * weights, (batch_size, h1_timesteps, mp_dim, embedding_size)\n",
    "        h1 = self._time_distributed_multiply(h1, w)\n",
    "        # attentive vector (batch_size, h1_timesteps, embedding_size)\n",
    "        attentive_vec = self._mean_attentive_vectors(h2, cosine_matrix)\n",
    "        # attentive_vec * weights, (batch_size, h1_timesteps, mp_dim, embedding_size)\n",
    "        attentive_vec = self._time_distributed_multiply(attentive_vec, w)\n",
    "        # matching vector, (batch_size, h1_timesteps, mp_dim)\n",
    "        h1 = K.l2_normalize(h1, axis=-1)\n",
    "        attentive_vec = K.l2_normalize(attentive_vec, axis=-1)\n",
    "        matching = K.sum(multiply([h1, attentive_vec]), axis=-1)\n",
    "        return matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim (x):\n",
    "    p = x[0] # [t, 2d]\n",
    "    q = x[1] # [j, 2d]\n",
    "    s = dot([p, K.permute_dimensions(q, (0,2,1))], axes=(2,1), normalize=True) # [t, j] cosine simlilarity\n",
    "    max_sim = K.max(s, axis=-1, keepdims=True) # [t, 1]\n",
    "    return max_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_model():\n",
    "    p = Input(shape=(maxlen_p,))\n",
    "    q = Input(shape=(maxlen_q,))\n",
    "    p_fea = Input(shape=(maxlen_p, features)) # passage word feature \n",
    "    \n",
    "    # Embedding layer\n",
    "    embed = Embedding(nb_words+1, embed_size, weights=[embedding_matrix], trainable=True)\n",
    "    ft = Embedding(nb_words+1, embed_size, weights=[fasttext_matrix], trainable=True)\n",
    "    pem = embed(p) # word embedding\n",
    "    pft = ft(p)\n",
    "    pe = Concatenate()([pem, pft])\n",
    "    qem = embed(q)\n",
    "    qft = ft(q)\n",
    "    qe = Concatenate()([qem, qft])\n",
    "    \n",
    "    p_cos_e = Lambda(cos_sim)([pem, qem])\n",
    "    p_cos_f = Lambda(cos_sim)([pft, qft])\n",
    "    pe = SpatialDropout1D(0.2)(pe)\n",
    "    qe = SpatialDropout1D(0.2)(qe)\n",
    "    pf = Concatenate()([pe, p_fea, p_cos_e, p_cos_f]) # passage feature vec = word embedding + (exact match + option match + cos sim)\n",
    "    \n",
    "    # Contextual embedding layer\n",
    "    h = Bidirectional(CuDNNLSTM(num_rnn_units, return_sequences=True))(pf) # [t, 2d]\n",
    "    u = Bidirectional(CuDNNLSTM(num_rnn_units, return_sequences=True))(qe) # [j,2d]\n",
    "\n",
    "    # Multi perspective matching layer\n",
    "    match = MultiPerspective(mp)\n",
    "    pm = match([h,u])\n",
    "    qm = match([u,h])\n",
    "    \n",
    "    # Aggregation layer\n",
    "    pa, phf, pcf, phb, pcb = Bidirectional(CuDNNLSTM(num_rnn_units, return_sequences=True, return_state=True))(pm) # [t, 2d], d, d, d, d\n",
    "    pam = GlobalMaxPooling1D()(pa) # [2d]\n",
    "    paa = GlobalAveragePooling1D()(pa) # [2d]\n",
    "    pc = Concatenate()([pam,paa,phf,phb])\n",
    "    \n",
    "    qa, qhf, qcf, qhb, qcb = Bidirectional(CuDNNLSTM(num_rnn_units, return_sequences=True, return_state=True))(qm) # [j, 2d], d, d, d, d\n",
    "    qam = GlobalMaxPooling1D()(qa) # [2d]\n",
    "    qaa = GlobalAveragePooling1D()(qa) # [2d]\n",
    "    qc = Concatenate()([qam,qaa,qhf,qhb])\n",
    "\n",
    "    # Output layer\n",
    "    conc = Concatenate()([pc, qc]) # [8d]\n",
    "    x = BatchNormalization()(conc)\n",
    "    x = Dense(num_hidden_units, activation='relu')(x)\n",
    "    x = Dropout(drop_prob)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    #x = Dense(num_hidden_units, activation='relu')(x)\n",
    "    #x = Dropout(drop_prob)(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=[p, q, p_fea], outputs=x)\n",
    "    #print (model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = single_model()\n",
    "model.load_weights('./model/my2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 750000 samples, validate on 90000 samples\n",
      "Epoch 1/3\n",
      "750000/750000 [==============================] - 1437s 2ms/step - loss: 0.3884 - binary_accuracy: 0.8233 - val_loss: 0.4063 - val_binary_accuracy: 0.8138\n",
      "Epoch 2/3\n",
      "750000/750000 [==============================] - 1435s 2ms/step - loss: 0.3384 - binary_accuracy: 0.8510 - val_loss: 0.4217 - val_binary_accuracy: 0.8118\n"
     ]
    }
   ],
   "source": [
    "adam = optimizers.Adam(lr=0.0002, clipnorm=max_norm)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['binary_accuracy'])\n",
    "    \n",
    "# train the model\n",
    "cp = ModelCheckpoint(filepath='./model/my2.h5', monitor='val_binary_accuracy', save_best_only=True, save_weights_only=True)\n",
    "es = EarlyStopping(patience=0,  monitor='val_binary_accuracy')\n",
    "#rp = ReduceLROnPlateau(patience = 1,  monitor='val_loss')\n",
    "hist = model.fit(\n",
    "    [train_p, train_q, train_feature], \n",
    "    train_l,\n",
    "    batch_size = batch_size,\n",
    "    epochs = 3,\n",
    "    shuffle = True,\n",
    "    validation_data = ([valid_p, valid_q, valid_feature], valid_l), \n",
    "    callbacks=[cp, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [0.40633796172671849, 0.42172297743161519], 'val_binary_accuracy': [0.81378888888888889, 0.81178888888888889], 'loss': [0.38839228627586364, 0.33835806921513878], 'binary_accuracy': [0.82334533333333337, 0.85099866666539514]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1de06da35f8>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (hist.history)\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(1)\n",
    "plt.plot (hist.history['binary_accuracy'])\n",
    "plt.plot (hist.history['val_binary_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the best weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./model/my2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict([test_p, test_q, test_feature], batch_size=batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29997,)\n"
     ]
    }
   ],
   "source": [
    "test_pred = np.squeeze(test_pred)\n",
    "print(test_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the array into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame({'id':test['id'], 'passage':test['passage'], 'query':test['query'], 'option':test['option'], 'label':test_pred})\n",
    "res.to_csv('./result/test2_long.csv', index=False, encoding='utf-8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
