{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc, random, math, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation, Dropout, Reshape, Flatten, Lambda, Permute\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import concatenate, Concatenate, multiply, Dot, subtract, add, dot\n",
    "from keras.layers import  GlobalMaxPooling1D, GlobalAveragePooling1D, Input, SpatialDropout1D, Bidirectional\n",
    "from keras.layers import CuDNNLSTM, CuDNNGRU, LSTM, GRU, Conv1D\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import optimizers, initializers, regularizers, constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 160000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen_p = 150 # max number of words in a context to use\n",
    "maxlen_q = 15 # max number of words in a question to use\n",
    "batch_size = 256\n",
    "num_rnn_units = 128\n",
    "num_hidden_units = 300\n",
    "drop_prob = 0.5\n",
    "max_norm = 5.0\n",
    "features = 2\n",
    "filter_sizes_p = [1,3,5]\n",
    "filter_sizes_q = [1,3]\n",
    "num_filters = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = './data/train.tsv' # train set\n",
    "valid_path = './data/valid.tsv' # validation set\n",
    "test_path = './data/test.tsv' # test set\n",
    "embed_file = './sgns.target.word-ngram.1-2.dynwin5.thr10.neg5.dim300.iter5' # 预训练词向量\n",
    "fasttext_file = './cc.zh.300.vec' # 预训练词向量\n",
    "train_feature_p_path = './data/train_fea_p.npy' # train passage word feature\n",
    "valid_feature_p_path = './data/valid_fea_p.npy' # validation passage word feature\n",
    "test_feature_p_path = './data/test_fea_p.npy' # test passage word feature\n",
    "train_feature_q_path = './data/train_fea_q.npy' # train passage word feature\n",
    "valid_feature_q_path = './data/valid_fea_q.npy' # validation passage word feature\n",
    "test_feature_q_path = './data/test_fea_q.npy' # test passage word feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000, 5) (90000, 5) (30000, 4)\n",
      "   id                                            passage  \\\n",
      "0   1  孩子 是 父母 的 一面镜子   由于 儿童 的 世界观 尚未 形成   他们 的 模仿 带...   \n",
      "1   1  孩子 是 父母 的 一面镜子   由于 儿童 的 世界观 尚未 形成   他们 的 模仿 带...   \n",
      "2   1  孩子 是 父母 的 一面镜子   由于 儿童 的 世界观 尚未 形成   他们 的 模仿 带...   \n",
      "3   2  目前   中国 很多 地方   学生 火车票 磁条 都 已经 升级 了   在 磁条 里 已...   \n",
      "4   2  目前   中国 很多 地方   学生 火车票 磁条 都 已经 升级 了   在 磁条 里 已...   \n",
      "\n",
      "                   query option  label  \n",
      "0   你 的 孩子 无法确定 保姆 带 大 的   无法确定      1  \n",
      "1      你 的 孩子 是 保姆 带 大 的      是      0  \n",
      "2     你 的 孩子 不是 保姆 带 大 的     不是      0  \n",
      "3  不是 一个 区间 刷 学生证 不能 有 票     不能      1  \n",
      "4   不是 一个 区间 刷 学生证 能 有 票      能      0  \n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(train_path, sep='\\t', header=0)\n",
    "valid = pd.read_csv(valid_path, sep='\\t', header=0)\n",
    "test = pd.read_csv(test_path, sep='\\t', header=0)\n",
    "print (train.shape, valid.shape, test.shape)\n",
    "print (train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000, 150, 2) (90000, 150, 2) (30000, 150, 2)\n",
      "(750000, 15, 2) (90000, 15, 2) (30000, 15, 2)\n"
     ]
    }
   ],
   "source": [
    "train_feature_p = np.load(train_feature_p_path)\n",
    "valid_feature_p = np.load(valid_feature_p_path)\n",
    "test_feature_p = np.load(test_feature_p_path)\n",
    "print (train_feature_p.shape, valid_feature_p.shape, test_feature_p.shape)\n",
    "train_feature_q = np.load(train_feature_q_path)\n",
    "valid_feature_q = np.load(valid_feature_q_path)\n",
    "test_feature_q = np.load(test_feature_q_path)\n",
    "print (train_feature_q.shape, valid_feature_q.shape, test_feature_q.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buld up the text input pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Fit the tokenizer on train, valid and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features, lower=True) \n",
    "\n",
    "tokenizer.fit_on_texts(pd.concat([train['passage'], train['query'], valid['passage'], valid['query'], test['passage'], test['query']], ignore_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1740000 167520\n"
     ]
    }
   ],
   "source": [
    "print (tokenizer.document_count, len(tokenizer.word_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text to seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tra_p = tokenizer.texts_to_sequences(train['passage'])\n",
    "tra_q = tokenizer.texts_to_sequences(train['query'])\n",
    "val_p = tokenizer.texts_to_sequences(valid['passage'])\n",
    "val_q = tokenizer.texts_to_sequences(valid['query'])\n",
    "te_p = tokenizer.texts_to_sequences(test['passage'])\n",
    "te_q = tokenizer.texts_to_sequences(test['query'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pad seq to maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_p = pad_sequences(tra_p, maxlen=maxlen_p)\n",
    "train_q = pad_sequences(tra_q, maxlen=maxlen_q, padding='post', truncating='post')\n",
    "valid_p = pad_sequences(val_p, maxlen=maxlen_p)\n",
    "valid_q = pad_sequences(val_q, maxlen=maxlen_q, padding='post', truncating='post')\n",
    "test_p = pad_sequences(te_p, maxlen=maxlen_p)\n",
    "test_q = pad_sequences(te_q, maxlen=maxlen_q, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000, 150) (750000, 15) (90000, 150) (90000, 15) (30000, 150) (30000, 15)\n"
     ]
    }
   ],
   "source": [
    "print (train_p.shape, train_q.shape, valid_p.shape, valid_q.shape, test_p.shape, test_q.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_l = train['label']\n",
    "valid_l = valid['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000,) (90000,)\n"
     ]
    }
   ],
   "source": [
    "print (train_l.shape, valid_l.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the pretrained word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.strip().split()) for o in open(embed_file, encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.014820942, 0.26983637)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embs = np.hstack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "emb_mean,emb_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words+1, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i > max_features: break\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.asarray(embedding_matrix, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fasttext_index = dict(get_coefs(*o.strip().split()) for o in open(fasttext_file, encoding='utf-8'))\n",
    "all_ft = np.hstack(fasttext_index.values())\n",
    "ft_mean,ft_std = all_ft.mean(), all_ft.std()\n",
    "fasttext_matrix = np.random.normal(ft_mean, ft_std, (nb_words+1, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i > max_features: break\n",
    "    fasttext_vector = fasttext_index.get(word)\n",
    "    if fasttext_vector is not None: fasttext_matrix[i] = fasttext_vector\n",
    "fasttext_matrix = np.asarray(fasttext_matrix, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Attetion layer\n",
    "class FeedForwardAttention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Keras Layer that implements an Attention mechanism for temporal data.\n",
    "        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n",
    "        # Input shape\n",
    "            3D tensor with shape: `(samples, steps, features)`.\n",
    "        # Output shape\n",
    "            2D tensor with shape: `(samples, features)`.\n",
    "        :param kwargs:\n",
    "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "        The dimensions are inferred based on the output shape of the RNN.\n",
    "        Example:\n",
    "            model.add(LSTM(64, return_sequences=True))\n",
    "            model.add(Attention())\n",
    "        \"\"\"\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(FeedForwardAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.softmax(eij)\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        #return input_shape[0], input_shape[-1]\n",
    "        return input_shape[0],  self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cos_sim (x):\n",
    "    p = x[0] # [t, 2d]\n",
    "    q = x[1] # [j, 2d]\n",
    "    s = dot([p, K.permute_dimensions(q, (0,2,1))], axes=(2,1), normalize=True) # [t, j] cosine simlilarity\n",
    "    max_sim = K.max(s, axis=-1, keepdims=True) # [t, 1]\n",
    "    return max_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def single_model():\n",
    "    p = Input(shape=(maxlen_p,))\n",
    "    q = Input(shape=(maxlen_q,))\n",
    "    p_fea = Input(shape=(maxlen_p, features)) # passage word feature (exact match + option match)\n",
    "    q_fea = Input(shape=(maxlen_q, features)) # query word feature\n",
    "    \n",
    "    # Embedding layer\n",
    "    embed = Embedding(nb_words+1, embed_size, weights=[embedding_matrix], trainable=False)\n",
    "    ft = Embedding(nb_words+1, embed_size, weights=[fasttext_matrix], trainable=False)\n",
    "    pem = embed(p) # word embedding\n",
    "    pft = ft(p)\n",
    "    pe = Concatenate()([pem, pft])\n",
    "    qem = embed(q)\n",
    "    qft = ft(q)\n",
    "    qe = Concatenate()([qem, qft])\n",
    "    \n",
    "    p_cos_e = Lambda(cos_sim)([pem, qem])\n",
    "    p_cos_f = Lambda(cos_sim)([pft, qft])\n",
    "    q_cos_e = Lambda(cos_sim)([qem, pem])\n",
    "    q_cos_f = Lambda(cos_sim)([qft, pft])\n",
    "    pe = SpatialDropout1D(0.2)(pe)\n",
    "    qe = SpatialDropout1D(0.2)(qe)\n",
    "    pf = Concatenate()([pe, p_fea, p_cos_e, p_cos_f]) # passage feature vec = word embedding + (exact match + option match + cos sim)\n",
    "    qe = Concatenate()([qe, q_fea, q_cos_e, q_cos_f]) # query feature vec = word embedding + (exact match + option match + cos sim)\n",
    "    \n",
    "    h = Bidirectional(CuDNNLSTM(num_rnn_units, return_sequences=True))(pf) # [t, 2d]\n",
    "    u = Bidirectional(CuDNNLSTM(num_rnn_units, return_sequences=True))(qe) # [j,2d]\n",
    "    \n",
    "    # cnn for p\n",
    "    convp_0 = Conv1D(num_filters, kernel_size=filter_sizes_p[0], padding = \"same\", activation = 'relu')(h)\n",
    "    convp_1 = Conv1D(num_filters, kernel_size=filter_sizes_p[1], padding = \"same\", activation = 'relu')(h)\n",
    "    convp_2 = Conv1D(num_filters, kernel_size=filter_sizes_p[2], padding = \"same\", activation = 'relu')(h)\n",
    "\n",
    "    maxpoolp_0 = GlobalMaxPooling1D()(convp_0)\n",
    "    avgpoolp_0 = GlobalAveragePooling1D()(convp_0)\n",
    "    attp_0 = FeedForwardAttention(maxlen_p)(convp_0)\n",
    "    maxpoolp_1 = GlobalMaxPooling1D()(convp_1)\n",
    "    avgpoolp_1 = GlobalAveragePooling1D()(convp_1)\n",
    "    attp_1 = FeedForwardAttention(maxlen_p)(convp_1)\n",
    "    maxpoolp_2 = GlobalMaxPooling1D()(convp_2)\n",
    "    avgpoolp_2 = GlobalAveragePooling1D()(convp_2)\n",
    "    attp_2 = FeedForwardAttention(maxlen_p)(convp_2)\n",
    "    zp = Concatenate()([maxpoolp_0, maxpoolp_1, maxpoolp_2, avgpoolp_0, avgpoolp_1, avgpoolp_2, attp_0, attp_1, attp_2])\n",
    "\n",
    "    # cnn for q\n",
    "    convq_0 = Conv1D(num_filters, kernel_size=filter_sizes_q[0], padding = \"same\", activation = 'relu')(u)\n",
    "    convq_1 = Conv1D(num_filters, kernel_size=filter_sizes_q[1], padding = \"same\", activation = 'relu')(u)\n",
    "\n",
    "    maxpoolq_0 = GlobalMaxPooling1D()(convq_0)\n",
    "    avgpoolq_0 = GlobalAveragePooling1D()(convq_0)\n",
    "    attq_0 = FeedForwardAttention(maxlen_q)(convq_0)\n",
    "    maxpoolq_1 = GlobalMaxPooling1D()(convq_1)\n",
    "    avgpoolq_1 = GlobalAveragePooling1D()(convq_1)\n",
    "    attq_1 = FeedForwardAttention(maxlen_q)(convq_1)\n",
    "    zq = Concatenate()([maxpoolq_0, maxpoolq_1, avgpoolq_0, avgpoolq_1, attq_0, attq_1])  \n",
    "    \n",
    "    # Output layer\n",
    "    x = Concatenate()([zp,zq])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(num_hidden_units, activation='relu')(x)\n",
    "    x = Dropout(drop_prob)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    #x = Dense(num_hidden_units, activation='relu')(x)\n",
    "    #x = Dropout(drop_prob)(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=[p, q, p_fea, q_fea], outputs=x)\n",
    "    #print (model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = single_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 750000 samples, validate on 90000 samples\n",
      "Epoch 1/12\n",
      "750000/750000 [==============================] - 357s 476us/step - loss: 0.4815 - binary_accuracy: 0.7629 - val_loss: 0.4255 - val_binary_accuracy: 0.7984\n",
      "Epoch 2/12\n",
      "750000/750000 [==============================] - 353s 470us/step - loss: 0.4099 - binary_accuracy: 0.8117 - val_loss: 0.4039 - val_binary_accuracy: 0.8162\n",
      "Epoch 3/12\n",
      "750000/750000 [==============================] - 352s 469us/step - loss: 0.3785 - binary_accuracy: 0.8292 - val_loss: 0.4141 - val_binary_accuracy: 0.8181\n",
      "Epoch 4/12\n",
      "750000/750000 [==============================] - 350s 467us/step - loss: 0.3309 - binary_accuracy: 0.8532 - val_loss: 0.4113 - val_binary_accuracy: 0.8241\n",
      "Epoch 5/12\n",
      "750000/750000 [==============================] - 350s 467us/step - loss: 0.3153 - binary_accuracy: 0.8605 - val_loss: 0.4115 - val_binary_accuracy: 0.8234\n",
      "Epoch 6/12\n",
      "750000/750000 [==============================] - 349s 466us/step - loss: 0.3135 - binary_accuracy: 0.8613 - val_loss: 0.4112 - val_binary_accuracy: 0.8234\n"
     ]
    }
   ],
   "source": [
    "adam = optimizers.Adam(lr=0.001, clipnorm=max_norm)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['binary_accuracy'])\n",
    "    \n",
    "# train the model\n",
    "cp = ModelCheckpoint(filepath='./model/my7.h5', monitor='val_binary_accuracy', save_best_only=True, save_weights_only=True)\n",
    "es = EarlyStopping(patience=2,  monitor='val_binary_accuracy')\n",
    "rp = ReduceLROnPlateau(patience = 1,  monitor='val_loss')\n",
    "hist = model.fit(\n",
    "    [train_p, train_q, train_feature_p, train_feature_q], \n",
    "    train_l,\n",
    "    batch_size = batch_size,\n",
    "    epochs = 12,\n",
    "    shuffle = True,\n",
    "    validation_data = ([valid_p, valid_q, valid_feature_p, valid_feature_q], valid_l), \n",
    "    callbacks=[rp, cp, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [0.42548004933463202, 0.4038706035984887, 0.41406389381620617, 0.4113156614144643, 0.41148010764122012, 0.41115611533588831], 'val_binary_accuracy': [0.79842222223281856, 0.81623333337571891, 0.81810000002119276, 0.82411111113230384, 0.82337777779897059, 0.82337777779897059], 'loss': [0.48149005356216429, 0.40989835236867267, 0.3784673367385864, 0.33089831596120201, 0.31529194336064659, 0.31354213838450112], 'binary_accuracy': [0.7629493333282471, 0.81174133332697551, 0.82916799999745683, 0.85318400000381467, 0.86052399999491369, 0.86130933332951864], 'lr': [0.001, 0.001, 0.001, 0.0001, 1.0000001e-05, 1.0000001e-06]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2d1b3ab31d0>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (hist.history)\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(1)\n",
    "plt.plot (hist.history['binary_accuracy'])\n",
    "plt.plot (hist.history['val_binary_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('./model/my7.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = model.predict([test_p, test_q, test_feature_p, test_feature_q], batch_size=batch_size*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000,)\n"
     ]
    }
   ],
   "source": [
    "test_pred = np.squeeze(test_pred)\n",
    "print(test_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for l in range(0, test_pred.shape[0], 3):\n",
    "    m = max(test_pred[l], test_pred[l+1], test_pred[l+2])\n",
    "    for i in range(3):\n",
    "        if test_pred[l+i] == m:\n",
    "            test_pred[l+i] = 1\n",
    "        else:\n",
    "            test_pred[l+i] = 0\n",
    "train_p = np.concatenate((train_p, test_p), axis=0)\n",
    "train_q = np.concatenate((train_q, test_q), axis=0)\n",
    "train_feature_p = np.concatenate((train_feature_p, test_feature_p), axis=0)\n",
    "train_feature_q = np.concatenate((train_feature_q, test_feature_q), axis=0)\n",
    "train_l = np.concatenate((train_l, test_pred), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the array into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame({'id':test['id'], 'passage':test['passage'], 'query':test['query'], 'option':test['option'], 'label':test_pred})\n",
    "res.to_csv('./result/test7_long.csv', index=False, encoding='utf-8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
