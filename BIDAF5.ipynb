{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc, random, math, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation, Dropout, Reshape, Flatten, Lambda, Permute\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import concatenate, Concatenate, multiply, Dot, dot\n",
    "from keras.layers import  GlobalMaxPooling1D, GlobalAveragePooling1D, Input, SpatialDropout1D, Bidirectional\n",
    "from keras.layers import CuDNNLSTM, CuDNNGRU, LSTM, GRU, Softmax\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 160000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen_p = 150 # max number of words in a context to use\n",
    "maxlen_q = 15 # max number of words in a question to use\n",
    "batch_size = 256\n",
    "num_rnn_units = 64\n",
    "num_hidden_units = 300\n",
    "drop_prob = 0.5\n",
    "max_norm = 5.0\n",
    "features = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = './data/train.tsv' # train set\n",
    "valid_path = './data/valid.tsv' # validation set\n",
    "test_path = './data/test.tsv' # test set\n",
    "embed_file = './sgns.target.word-ngram.1-2.dynwin5.thr10.neg5.dim300.iter5' # 预训练词向量\n",
    "fasttext_file = './cc.zh.300.vec' # 预训练词向量\n",
    "train_feature_path = './data/train_fea.npy' # train passage word feature\n",
    "valid_feature_path = './data/valid_fea.npy' # validation passage word feature\n",
    "test_feature_path = './data/test_fea.npy' # test passage word feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000, 5) (90000, 5) (29997, 4)\n",
      "   id                                            passage  \\\n",
      "0   1  孩子 是 父母 的 一面镜子   由于   的 世界观 尚未 形成   他们   模仿 带有...   \n",
      "1   1  孩子 是 父母 的 一面镜子   由于 儿童 的 世界观 尚未 形成   他们 的 模仿 带...   \n",
      "2   1  孩子 是 父母 的 一面镜子   由于   的 世界观 尚未 形成   他们 的 模仿 带有...   \n",
      "3   2  目前   中国 很多 地方   学生 火车票 磁条 都 已经 升级 了   在 磁条 里  ...   \n",
      "4   2  目前   中国 很多     学生 火车票 磁条 都 已经 升级 了   在 磁条 里 已经...   \n",
      "\n",
      "                   query option  label  \n",
      "0   你 的 孩子 无法确定 保姆 带 大 的   无法确定      1  \n",
      "1      你 的 孩子 是 保姆 带 大 的      是      0  \n",
      "2     你 的 孩子 不是 保姆 带 大 的     不是      0  \n",
      "3  不是 一个 区间 刷 学生证 不能 有 票     不能      1  \n",
      "4   不是 一个 区间 刷 学生证 能 有 票      能      0  \n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(train_path, sep='\\t', header=0)\n",
    "valid = pd.read_csv(valid_path, sep='\\t', header=0)\n",
    "test = pd.read_csv(test_path, sep='\\t', header=0)\n",
    "print (train.shape, valid.shape, test.shape)\n",
    "print (train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000, 150, 2) (90000, 150, 2) (29997, 150, 2)\n"
     ]
    }
   ],
   "source": [
    "train_feature = np.load(train_feature_path)\n",
    "valid_feature = np.load(valid_feature_path)\n",
    "test_feature = np.load(test_feature_path)\n",
    "print (train_feature.shape, valid_feature.shape, test_feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buld up the text input pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Fit the tokenizer on train, valid and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features, lower=True) \n",
    "\n",
    "tokenizer.fit_on_texts(pd.concat([train['passage'], train['query'], valid['passage'], valid['query'], test['passage'], test['query']], ignore_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1739994 172745\n"
     ]
    }
   ],
   "source": [
    "print (tokenizer.document_count, len(tokenizer.word_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text to seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tra_p = tokenizer.texts_to_sequences(train['passage'])\n",
    "tra_q = tokenizer.texts_to_sequences(train['query'])\n",
    "val_p = tokenizer.texts_to_sequences(valid['passage'])\n",
    "val_q = tokenizer.texts_to_sequences(valid['query'])\n",
    "te_p = tokenizer.texts_to_sequences(test['passage'])\n",
    "te_q = tokenizer.texts_to_sequences(test['query'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pad seq to maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_p = pad_sequences(tra_p, maxlen=maxlen_p)\n",
    "train_q = pad_sequences(tra_q, maxlen=maxlen_q, padding='post', truncating='post')\n",
    "valid_p = pad_sequences(val_p, maxlen=maxlen_p)\n",
    "valid_q = pad_sequences(val_q, maxlen=maxlen_q, padding='post', truncating='post')\n",
    "test_p = pad_sequences(te_p, maxlen=maxlen_p)\n",
    "test_q = pad_sequences(te_q, maxlen=maxlen_q, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000, 150) (750000, 10) (90000, 150) (90000, 10) (29997, 150) (29997, 10)\n"
     ]
    }
   ],
   "source": [
    "print (train_p.shape, train_q.shape, valid_p.shape, valid_q.shape, test_p.shape, test_q.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_l = train['label']\n",
    "valid_l = valid['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000,) (90000,)\n"
     ]
    }
   ],
   "source": [
    "print (train_l.shape, valid_l.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the pretrained word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.strip().split()) for o in open(embed_file, encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.014820942, 0.26983637)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embs = np.hstack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "emb_mean,emb_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words+1, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i > max_features: break\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.asarray(embedding_matrix, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fasttext_index = dict(get_coefs(*o.strip().split()) for o in open(fasttext_file, encoding='utf-8'))\n",
    "all_ft = np.hstack(fasttext_index.values())\n",
    "ft_mean,ft_std = all_ft.mean(), all_ft.std()\n",
    "fasttext_matrix = np.random.normal(ft_mean, ft_std, (nb_words+1, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i > max_features: break\n",
    "    fasttext_vector = fasttext_index.get(word)\n",
    "    if fasttext_vector is not None: fasttext_matrix[i] = fasttext_vector\n",
    "fasttext_matrix = np.asarray(fasttext_matrix, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attention_flow (x):\n",
    "    h = x[0]\n",
    "    u = x[1]\n",
    "    s = K.batch_dot(h, K.permute_dimensions(u, (0,2,1)), axes=[2,1]) # [t, j]\n",
    "    p2q = K.batch_dot(K.softmax(s, axis=-1), u, axes=[2,1]) # [t, 2d]\n",
    "    b = K.softmax(K.max(s, axis=-1, keepdims=True), -2) # [t, 1]\n",
    "    q2p = K.tile(K.batch_dot(K.permute_dimensions(h, (0,2,1)), b, axes=[2,1]), [1, 1, K.int_shape(h)[1]]) # [2d, t]\n",
    "    h_p2q = multiply([h, p2q]) # [t, 2d]\n",
    "    h_q2p = multiply([h, K.permute_dimensions(q2p, (0,2,1))]) # [t, 2d]\n",
    "    g = concatenate([h, p2q, h_p2q, h_q2p]) # [t, 8d]\n",
    "    '''\n",
    "    # self-attention\n",
    "    sg = K.batch_dot(g, K.permute_dimensions(g, (0,2,1)), axes=[2,1]) # [t, t]\n",
    "    g = K.batch_dot(K.softmax(sg, axis=-1), g, axes=[2,1]) # [t, 8d]\n",
    "    '''\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cos_sim (x):\n",
    "    p = x[0] # [t, 2d]\n",
    "    q = x[1] # [j, 2d]\n",
    "    s = dot([p, K.permute_dimensions(q, (0,2,1))], axes=(2,1), normalize=True) # [t, j] cosine simlilarity\n",
    "    max_sim = K.max(s, axis=-1, keepdims=True) # [t, 1]\n",
    "    return max_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def single_model():\n",
    "    p = Input(shape=(maxlen_p,))\n",
    "    q = Input(shape=(maxlen_q,))\n",
    "    p_fea = Input(shape=(maxlen_p, features)) # passage word feature \n",
    "    \n",
    "    # Embedding layer\n",
    "    embed = Embedding(nb_words+1, embed_size, weights=[embedding_matrix], trainable=False)\n",
    "    ft = Embedding(nb_words+1, embed_size, weights=[fasttext_matrix], trainable=False)\n",
    "    pem = embed(p) # word embedding\n",
    "    pft = ft(p)\n",
    "    pe = Concatenate()([pem, pft])\n",
    "    qem = embed(q)\n",
    "    qft = ft(q)\n",
    "    qe = Concatenate()([qem, qft])\n",
    "    \n",
    "    p_cos_e = Lambda(cos_sim)([pem, qem])\n",
    "    p_cos_f = Lambda(cos_sim)([pft, qft])\n",
    "    pe = SpatialDropout1D(0.2)(pe)\n",
    "    qe = SpatialDropout1D(0.2)(qe)\n",
    "    pf = Concatenate()([pe, p_fea, p_cos_e, p_cos_f]) # passage feature vec = word embedding + (exact match + option match + cos sim)\n",
    "    \n",
    "    # Contextual embedding layer\n",
    "    h = Bidirectional(CuDNNLSTM(num_rnn_units, return_sequences=True))(pf) # [t, 2d]\n",
    "    u = Bidirectional(CuDNNLSTM(num_rnn_units, return_sequences=True))(qe) # [j,2d]\n",
    "    \n",
    "    # Attention flow layer\n",
    "    g = Lambda(attention_flow)([h, u]) # [t, 8d]\n",
    "    \n",
    "    # Modelling layer\n",
    "    m, hf, cf, hb, cb = Bidirectional(CuDNNLSTM(num_rnn_units, return_sequences=True, return_state=True))(g) # [t, 2d], d, d, d, d\n",
    "    #m = Bidirectional(CuDNNLSTM(num_rnn_units, return_sequences=True))(m) # [t, 2d]\n",
    "    \n",
    "    um, uhf, ucf, uhb, ucb = Bidirectional(CuDNNLSTM(num_rnn_units, return_sequences=True, return_state=True))(u) # [j,2d], d, d, d, d\n",
    "\n",
    "    # Output layer\n",
    "    conc = Concatenate()([g, m]) # [t, 10d]\n",
    "    gmp = GlobalMaxPooling1D()(conc) # [10d]\n",
    "    gap = GlobalAveragePooling1D()(conc) # [10d]\n",
    "    z1 = Concatenate()([gmp, gap, hf, hb]) # [22d]\n",
    "    \n",
    "    ugmp = GlobalMaxPooling1D()(um) # [2d]\n",
    "    ugap = GlobalAveragePooling1D()(um) # [2d]\n",
    "    z2 = Concatenate()([ugmp, ugap, uhf, uhb]) # [6d]\n",
    "\n",
    "    y = Concatenate()([z1, z2])\n",
    "    x = BatchNormalization()(y)\n",
    "    x = Dense(num_hidden_units, activation='relu')(x)\n",
    "    x = Dropout(drop_prob)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    #x = Dense(num_hidden_units, activation='relu')(x)\n",
    "    #x = Dropout(drop_prob)(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=[p, q, p_fea], outputs=x)\n",
    "    print (model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 150)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         multiple             48000300    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 150, 300)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 150, 2)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 150, 1)       0           embedding_1[0][0]                \n",
      "                                                                 embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 150, 303)     0           spatial_dropout1d_1[0][0]        \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 10, 300)      0           embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 150, 128)     188928      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 10, 128)      187392      spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 150, 512)     0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) [(None, 150, 128), ( 295936      lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 150, 640)     0           lambda_2[0][0]                   \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 640)          0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 640)          0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1408)         0           global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "                                                                 bidirectional_3[0][1]            \n",
      "                                                                 bidirectional_3[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1408)         5632        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 300)          422700      batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 300)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 300)          1200        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            301         batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 49,102,389\n",
      "Trainable params: 1,098,673\n",
      "Non-trainable params: 48,003,716\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 750000 samples, validate on 90000 samples\n",
      "Epoch 1/12\n",
      "750000/750000 [==============================] - 270s 360us/step - loss: 0.5106 - binary_accuracy: 0.7378 - val_loss: 0.4692 - val_binary_accuracy: 0.7702\n",
      "Epoch 2/12\n",
      "750000/750000 [==============================] - 266s 355us/step - loss: 0.4510 - binary_accuracy: 0.7840 - val_loss: 0.4319 - val_binary_accuracy: 0.7952\n",
      "Epoch 3/12\n",
      "750000/750000 [==============================] - 266s 355us/step - loss: 0.4275 - binary_accuracy: 0.7995 - val_loss: 0.4187 - val_binary_accuracy: 0.8037\n",
      "Epoch 4/12\n",
      "750000/750000 [==============================] - 266s 355us/step - loss: 0.4105 - binary_accuracy: 0.8093 - val_loss: 0.4159 - val_binary_accuracy: 0.8064\n",
      "Epoch 5/12\n",
      "750000/750000 [==============================] - 266s 355us/step - loss: 0.3958 - binary_accuracy: 0.8180 - val_loss: 0.4173 - val_binary_accuracy: 0.8074 loss: 0.39\n",
      "Epoch 6/12\n",
      "750000/750000 [==============================] - 266s 355us/step - loss: 0.3706 - binary_accuracy: 0.8304 - val_loss: 0.4140 - val_binary_accuracy: 0.8101\n",
      "Epoch 7/12\n",
      "750000/750000 [==============================] - 267s 356us/step - loss: 0.3648 - binary_accuracy: 0.8339 - val_loss: 0.4154 - val_binary_accuracy: 0.8112\n",
      "Epoch 8/12\n",
      "750000/750000 [==============================] - 267s 356us/step - loss: 0.3601 - binary_accuracy: 0.8363 - val_loss: 0.4158 - val_binary_accuracy: 0.8111\n",
      "Epoch 9/12\n",
      "750000/750000 [==============================] - 267s 356us/step - loss: 0.3596 - binary_accuracy: 0.8368 - val_loss: 0.4156 - val_binary_accuracy: 0.8114\n",
      "Epoch 10/12\n",
      "750000/750000 [==============================] - 267s 356us/step - loss: 0.3594 - binary_accuracy: 0.8369 - val_loss: 0.4161 - val_binary_accuracy: 0.8112\n",
      "Epoch 11/12\n",
      "750000/750000 [==============================] - 267s 356us/step - loss: 0.3591 - binary_accuracy: 0.8365 - val_loss: 0.4159 - val_binary_accuracy: 0.8112\n",
      "Epoch 12/12\n",
      "750000/750000 [==============================] - 268s 357us/step - loss: 0.3598 - binary_accuracy: 0.8364 - val_loss: 0.4160 - val_binary_accuracy: 0.8112\n"
     ]
    }
   ],
   "source": [
    "adam = optimizers.Adam(lr=0.001, clipnorm=max_norm)\n",
    "model = single_model()\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['binary_accuracy'])\n",
    "    \n",
    "# train the model\n",
    "cp = ModelCheckpoint(filepath='./model/my5.h5', monitor='val_binary_accuracy', save_best_only=True, save_weights_only=True)\n",
    "es = EarlyStopping(patience=2,  monitor='val_binary_accuracy')\n",
    "rp = ReduceLROnPlateau(patience = 1,  monitor='val_loss')\n",
    "hist = model.fit(\n",
    "    [train_p, train_q, train_feature], \n",
    "    train_l,\n",
    "    batch_size = batch_size,\n",
    "    epochs = 12,\n",
    "    shuffle = True,\n",
    "    validation_data = ([valid_p, valid_q, valid_feature], valid_l), \n",
    "    callbacks=[rp, cp, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [0.46924280989964801, 0.43191785909864638, 0.41874387148751152, 0.41591235136455962, 0.41731481414371069, 0.41401120999654134, 0.4154146952946981, 0.41576831067403158, 0.41563533696068655, 0.41605748842027451, 0.41589798924128213, 0.41604672534730697], 'val_binary_accuracy': [0.77016666664547395, 0.79519999998940361, 0.80369999995761443, 0.80644444442325169, 0.80738888893127436, 0.81010000000000004, 0.81118888888888885, 0.81113333334392967, 0.81135555556615191, 0.81118888885709972, 0.81118888885709972, 0.81117777778837419], 'loss': [0.5106492753505707, 0.45100101271311444, 0.4275403757826487, 0.4104632830060323, 0.3957577587858836, 0.37061961306889851, 0.36484785449918111, 0.36013829030672712, 0.35964419274075826, 0.3594077334493001, 0.35914260971895856, 0.35984904386138916], 'binary_accuracy': [0.7378480000012716, 0.7839919999961853, 0.79945733333460489, 0.8093200000050863, 0.81801600000127161, 0.83041333332951861, 0.83390933332824702, 0.83629733333587641, 0.83675333333079016, 0.83691866666412351, 0.83651733333333333, 0.83640533333969114], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 1.0000001e-05, 1.0000001e-06, 1.0000001e-07, 1.0000001e-08, 1.0000001e-09]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b838d65080>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (hist.history)\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(1)\n",
    "plt.plot (hist.history['binary_accuracy'])\n",
    "plt.plot (hist.history['val_binary_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the best weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('./model/my5.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = model.predict([test_p, test_q, test_feature], batch_size=batch_size*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29997,)\n"
     ]
    }
   ],
   "source": [
    "test_pred = np.squeeze(test_pred)\n",
    "print(test_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the array into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame({'id':test['id'], 'passage':test['passage'], 'query':test['query'], 'option':test['option'], 'label':test_pred})\n",
    "res.to_csv('./result/test22_long.csv', index=False, encoding='utf-8_sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check validation prediction result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val_pred = model.predict([valid_p, valid_q, valid_feature], batch_size=batch_size*4)\n",
    "val_pred = np.squeeze(val_pred)\n",
    "res = pd.DataFrame({'id':valid['id'], 'passage':valid['passage'], 'query':valid['query'], 'option':valid['option'], 'label':val_pred})\n",
    "res.to_csv('./result/valid17_long.csv', index=False, encoding='utf-8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
