{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MRC with BERT on GPU.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "mQrZ_2YXXlZI",
        "_DOEWwhTrLyV"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "0n1bcX-r3yBS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Run the BERT fine tuning on GPU for the mrc competition. "
      ]
    },
    {
      "metadata": {
        "id": "2veMHwkHYY0M",
        "colab_type": "code",
        "outputId": "de7bab12-5c46-40a2-9f70-9acf51c66fea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hCtXrGSPvsrr",
        "colab_type": "code",
        "outputId": "aa1bcdf3-df2d-4857-fe1c-50ee9784119e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "d640766de8f4ead8f2e2c09aac3950c19f880f29",
        "id": "mQrZ_2YXXlZI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocess"
      ]
    },
    {
      "metadata": {
        "id": "m8S9eMPSaSjV",
        "colab_type": "code",
        "outputId": "01b914b7-2860-4c0e-b77f-b26cb1648078",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install jieba"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jieba\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/46/c6f9179f73b818d5827202ad1c4a94e371a29473b7f043b736b4dab6b8cd/jieba-0.39.zip (7.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 7.3MB 5.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: jieba\n",
            "  Running setup.py bdist_wheel for jieba ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/c9/c7/63/a9ec0322ccc7c365fd51e475942a82395807186e94f0522243\n",
            "Successfully built jieba\n",
            "Installing collected packages: jieba\n",
            "Successfully installed jieba-0.39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "A28M9xlaXlZL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import jieba\n",
        "import zipfile\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import sys\n",
        "import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5cea0ec0a6109549a0c5b9698e84049a13374f72",
        "id": "uJW0vS1mXlZR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/My Drive/Colab Notebooks/ai_challenger_oqmrc_trainingset.json' # train set\n",
        "valid_path = '/content/drive/My Drive/Colab Notebooks/ai_challenger_oqmrc_validationset.json' # validation set\n",
        "test_path = '/content/drive/My Drive/Colab Notebooks/ai_challenger_oqmrc_testa.json' # test set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dfe256de630ecd50e3903c61b7fc60a8574d74fd",
        "id": "zFbkKGtqXlZV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_set = pd.read_json(train_path, orient='records', encoding='utf-8', lines=True)\n",
        "valid_set = pd.read_json(valid_path, orient='records', encoding='utf-8', lines=True)\n",
        "test_set = pd.read_json(test_path, orient='records', encoding='utf-8', lines=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7606172009ed985fbd2fa268b3ccf64557386829",
        "id": "dh25wqDhXlZX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess(text, alternatives, aug=False):\n",
        "    jieba.suggest_freq(('不', '会'), tune=True)\n",
        "    jieba.suggest_freq(('不', '能'), tune=True)\n",
        "    jieba.suggest_freq(('不', '行'), tune=True)\n",
        "    jieba.suggest_freq(('不', '好'), tune=True)\n",
        "    jieba.suggest_freq(('不', '要'), tune=True)\n",
        "    jieba.suggest_freq(('不', '是'), tune=True)\n",
        "    jieba.suggest_freq(('不'), tune=True)\n",
        "    jieba.suggest_freq('无法确定', tune=True)\n",
        "    sent = jieba.lcut(text, HMM=False)\n",
        "\n",
        "    for i in range(len(sent)):\n",
        "        if sent[i] in \"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）《》“”：【】]+\":\n",
        "            sent[i] = ' '\n",
        "        elif aug and random.random()<0.1: # data augmentation\n",
        "            sent[i] = ' '\n",
        "        else:\n",
        "            sent[i].lower()\n",
        "    sent = ' '.join(sent)\n",
        "    return sent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c34642183940ffa628313cfa97ded5f6b1b65f01",
        "id": "6HJ6q_-dXlZZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# concatenate query and alternatives\n",
        "def query_alt(query, alternatives, a):\n",
        "    '''\n",
        "    query: line['query'] from original dataframe\n",
        "    alternatives: line['alternatives'] from original dataframe\n",
        "    a: current option in alternatives to be merged with query\n",
        "    \n",
        "    return: query and current option a concatenated (preprocessed)\n",
        "    '''\n",
        "    \n",
        "    query = query.strip()\n",
        "    if query[-1] == \"吗\" or query[-1] == \"么\" or query[-1] == \"嘛\" or query[-1] == \"不\": \n",
        "        query = query[:-1]\n",
        "        match = None\n",
        "        o = alternatives.split('|')\n",
        "        o = [m.strip() for m in o]\n",
        "        if '无法确认' in o:\n",
        "            o.remove('无法确认')\n",
        "        if '无法确定' in o:\n",
        "            o.remove('无法确定') \n",
        "        if o[0] in o[1]:\n",
        "            long = o[1]\n",
        "            short = o[0]\n",
        "        else:\n",
        "            long = o[0]\n",
        "            short = o[1]\n",
        "        if long in query:\n",
        "            match = long\n",
        "        else:\n",
        "            if short in query:\n",
        "                match = short\n",
        "            elif (short == '能') and ('可以' in query):\n",
        "                match = '可以'\n",
        "            elif (short == '可以') and ('能' in query):\n",
        "                match = '能'\n",
        "            elif (short == '可以') and ('会' in query):\n",
        "                match = '会'\n",
        "            elif (short == '会') and ('可以' in query):\n",
        "                match = '可以'\n",
        "            elif (short == '会') and ('能' in query):\n",
        "                match = '能'\n",
        "            elif (short == '能') and ('会' in query):\n",
        "                match = '会'\n",
        "\n",
        "        if match:\n",
        "            query = query.replace(match, a)\n",
        "        else:\n",
        "            query = a + query\n",
        "            \n",
        "        merged = preprocess(query, alternatives)\n",
        "        return merged\n",
        "            \n",
        "    else: # 问题里正反两个词都要替换\n",
        "        match = alternatives.split('|')\n",
        "        match = [m.strip() for m in match]\n",
        "        if '无法确认' in match:\n",
        "            match.remove('无法确认')\n",
        "        if '无法确定' in match:\n",
        "            match.remove('无法确定') \n",
        "        if match[0] in query and match[1] in query: # 两个词都出现了\n",
        "            if match[0] + match[1] in query: # 有没有，会不会\n",
        "                query = query.replace(match[0] + match[1], a)\n",
        "            elif match[1] + match[0] in query:\n",
        "                query = query.replace(match[1] + match[0], a)\n",
        "            else: # A好还是B好\n",
        "                if a == match[0]:\n",
        "                    query = query.replace(match[1], ' ')\n",
        "                elif a == match[1]:\n",
        "                    query = query.replace(match[0], ' ')\n",
        "                else: # 无法确定\n",
        "                    query = query.replace(match[0], ' ')\n",
        "                    query = query.replace(match[1], a)\n",
        "        else: # 两个词没完整出现\n",
        "            if '能否' in query:\n",
        "                query = query.replace('能否', a)\n",
        "            elif '是否' in query:\n",
        "                query = query.replace('是否', a)\n",
        "            elif '可否' in query:\n",
        "                query = query.replace('可否', a)\n",
        "            \n",
        "        merged = preprocess(query, alternatives)\n",
        "        return merged"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5da62335218557a469de31e428b5395bd0bdc84e",
        "id": "1AZFk3WFXlZb",
        "colab_type": "code",
        "outputId": "40fc8751-c49d-45cf-b1a7-b981c2efe1dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "with open('train.tsv', 'w', encoding='utf-8') as fw:\n",
        "    fw.write('id' + '\\t' + 'passage' + '\\t' + 'query' + '\\t' + 'option' + '\\t' + 'label' + '\\n')\n",
        "    for i in tqdm(range(train_set.shape[0])):\n",
        "        line = train_set.iloc[i]\n",
        "        p = preprocess(line['passage'], line['alternatives'])\n",
        "        for a in line['alternatives'].split('|'):\n",
        "            a = a.strip()\n",
        "            m = query_alt(query=line['query'], alternatives=line['alternatives'], a=a)\n",
        "            if a == line['answer'].strip():\n",
        "                fw.write(str(line['query_id'])+ '\\t'+ p+ '\\t'+ m+ '\\t'+ a+ '\\t'+ '1'+'\\n')\n",
        "            else:\n",
        "                fw.write(str(line['query_id'])+ '\\t'+ p+ '\\t'+ m+ '\\t'+ a+ '\\t'+ '0'+'\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/250000 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 1.030 seconds.\n",
            "Prefix dict has been built succesfully.\n",
            "100%|██████████| 250000/250000 [06:33<00:00, 635.86it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d279d9624c2ca75bc8cb7ca77953a775673d8b52",
        "id": "gWDo0w9jXlZe",
        "colab_type": "code",
        "outputId": "f1b18d60-6aa7-4483-c451-bb21125b295e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "with open('valid.tsv', 'w', encoding='utf-8') as fw:\n",
        "    fw.write('id' + '\\t' + 'passage' + '\\t' + 'query' + '\\t' + 'option' + '\\t' + 'label' + '\\n')\n",
        "    for i in tqdm(range(valid_set.shape[0])):\n",
        "        line = valid_set.iloc[i]\n",
        "        p = preprocess(line['passage'], line['alternatives'])\n",
        "        for a in line['alternatives'].split('|'):\n",
        "            a = a.strip()\n",
        "            m = query_alt(query=line['query'], alternatives=line['alternatives'], a=a)\n",
        "            if a == line['answer'].strip():\n",
        "                fw.write(str(line['query_id'])+ '\\t'+ p+ '\\t'+ m+ '\\t'+ a+ '\\t'+ '1'+'\\n')\n",
        "            else:\n",
        "                fw.write(str(line['query_id'])+ '\\t'+ p+ '\\t'+ m+ '\\t'+ a+ '\\t'+ '0'+'\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30000/30000 [00:47<00:00, 635.40it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eacdafe992228b668f07194211feb8bbd49f334a",
        "id": "mihrVEUbXlZg",
        "colab_type": "code",
        "outputId": "1349678b-d867-410b-db38-1065ffa699fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "with open('test.tsv', 'w', encoding='utf-8') as fw:\n",
        "    fw.write('id' + '\\t' + 'passage' + '\\t' + 'query' + '\\t'+ 'option'+ '\\n')\n",
        "    for i in tqdm(range(test_set.shape[0])):\n",
        "        line = test_set.iloc[i]\n",
        "        p = preprocess(line['passage'], line['alternatives'])\n",
        "        for a in line['alternatives'].split('|'):\n",
        "            a = a.strip()\n",
        "            m = query_alt(query=line['query'], alternatives=line['alternatives'], a=a)\n",
        "            fw.write(str(line['query_id'])+ '\\t'+ p+ '\\t'+ m+ '\\t'+ a+ '\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:15<00:00, 650.66it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "2ae14977b40c20d532444d93301b46b11799ffe6",
        "id": "JLe4P_iYXlZi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## BERT files"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "QvKDrYmcXlZk",
        "colab_type": "code",
        "outputId": "86bac488-c0df-4b0a-f9eb-c495461c246a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "#downloading weights and cofiguration file for the model\n",
        "!wget https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-03 00:51:24--  https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.187.128, 2404:6800:4008:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.187.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 381892918 (364M) [application/zip]\n",
            "Saving to: ‘chinese_L-12_H-768_A-12.zip’\n",
            "\n",
            "chinese_L-12_H-768_ 100%[===================>] 364.20M  50.4MB/s    in 8.6s    \n",
            "\n",
            "2018-12-03 00:51:34 (42.4 MB/s) - ‘chinese_L-12_H-768_A-12.zip’ saved [381892918/381892918]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8cf1f5466e25bbf042e0b6d55355d0bf7f02984e",
        "id": "5YDGgYqgXlZm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "repo = 'model_repo'\n",
        "with zipfile.ZipFile(\"chinese_L-12_H-768_A-12.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(repo)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b4a8b81c1fb8b5fae20945a56fda981550c54342",
        "id": "NNEAA5p2XlZn",
        "colab_type": "code",
        "outputId": "e762ba34-39aa-4957-af8e-9d69a88253be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "!ls 'model_repo/chinese_L-12_H-768_A-12'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert_config.json\t\t     bert_model.ckpt.index  vocab.txt\n",
            "bert_model.ckpt.data-00000-of-00001  bert_model.ckpt.meta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4ebe4f1dee0cf2b59c0b02981d42527be27f2395",
        "id": "eD9elzqiXlZ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import modeling\n",
        "import optimization\n",
        "import run_classifier\n",
        "import tokenization\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uZdI6TMNCCl1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Hyper parameter"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0f47047973d523029fbe9c355577133c4656ce57",
        "id": "pkxlQzUnXlZt",
        "colab_type": "code",
        "outputId": "2c0dce36-0c71-48f1-f0b0-0409033ec81e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "repo = 'model_repo'\n",
        "BERT_MODEL = 'chinese_L-12_H-768_A-12'\n",
        "BERT_PRETRAINED_DIR = f'{repo}/chinese_L-12_H-768_A-12'\n",
        "OUTPUT_DIR = f'{repo}/outputs'\n",
        "print(f'***** Model output directory: {OUTPUT_DIR} *****')\n",
        "print(f'***** BERT pretrained directory: {BERT_PRETRAINED_DIR} *****')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: model_repo/outputs *****\n",
            "***** BERT pretrained directory: model_repo/chinese_L-12_H-768_A-12 *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wGxnKwb0B7Ux",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Model Hyper Parameters\n",
        "BATCH_SIZE = 90\n",
        "epoch = 2\n",
        "LEARNING_RATE = 5e-5\n",
        "WARMUP_PROPORTION = 0.1\n",
        "MAX_SEQ_LENGTH = 64\n",
        "VOCAB_FILE = os.path.join(BERT_PRETRAINED_DIR, 'vocab.txt')\n",
        "CONFIG_FILE = os.path.join(BERT_PRETRAINED_DIR, 'bert_config.json')\n",
        "INIT_CHECKPOINT = os.path.join(BERT_PRETRAINED_DIR, 'bert_model.ckpt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "68f9932a52af968d1e94d0e115fc06e3423e1d47",
        "id": "NTTTHCxAXlZs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data generation"
      ]
    },
    {
      "metadata": {
        "id": "_DOEWwhTrLyV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load tsv files"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3a2a0d12de6ecb82812a36549ea910b5a55c0c4a",
        "id": "7zFFaGCDXlZw",
        "colab_type": "code",
        "outputId": "e353626f-f7c8-41ad-af70-fdeb490a5366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "train_path = 'train.tsv' # train set\n",
        "valid_path = 'valid.tsv' # validation set\n",
        "test_path = 'test.tsv' # test set\n",
        "train = pd.read_csv(train_path, sep='\\t', header=0)\n",
        "valid = pd.read_csv(valid_path, sep='\\t', header=0)\n",
        "test = pd.read_csv(test_path, sep='\\t', header=0)\n",
        "print (train.shape, valid.shape, test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(750000, 5) (90000, 5) (30000, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ffe3025296791b3328873707a4930e563e050a78",
        "id": "K9c4PiamXlZy",
        "colab_type": "code",
        "outputId": "6354ab3d-6fa2-412e-8837-e122a897147f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "cell_type": "code",
      "source": [
        "print (train.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   id                                            passage  \\\n",
            "0   1  孩子 是 父母 的 一面镜子   由于 儿童 的 世界观 尚未 形成   他们 的 模仿 带...   \n",
            "1   1  孩子 是 父母 的 一面镜子   由于 儿童 的 世界观 尚未 形成   他们 的 模仿 带...   \n",
            "2   1  孩子 是 父母 的 一面镜子   由于 儿童 的 世界观 尚未 形成   他们 的 模仿 带...   \n",
            "3   2  目前   中国 很多 地方   学生 火车票 磁条 都 已经 升级 了   在 磁条 里 已...   \n",
            "4   2  目前   中国 很多 地方   学生 火车票 磁条 都 已经 升级 了   在 磁条 里 已...   \n",
            "\n",
            "                   query option  label  \n",
            "0   你 的 孩子 无法确定 保姆 带 大 的   无法确定      1  \n",
            "1      你 的 孩子 是 保姆 带 大 的      是      0  \n",
            "2     你 的 孩子 不是 保姆 带 大 的     不是      0  \n",
            "3  不是 一个 区间 刷 学生证 不能 有 票     不能      1  \n",
            "4   不是 一个 区间 刷 学生证 能 有 票      能      0  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2DNoLsTBrPt8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create BERT input examples"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "25a7a93f4fe184d0f97e5ffa2fa993421bc542d0",
        "id": "oq0ooXCnXlZ4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_examples(set_type):\n",
        "#Generate data for the BERT model\n",
        "    if set_type == 'train':\n",
        "        lines = train\n",
        "    elif set_type == 'valid':\n",
        "        lines = valid\n",
        "    else:\n",
        "        lines = test\n",
        "    examples = []\n",
        "    for i in range(0, lines.shape[0], 3):\n",
        "        line3 = lines.iloc[i:i+3]\n",
        "        if set_type == 'train':\n",
        "            line3 = line3.sample(frac=1) # need to shuffle the train set, otherwise the first answer\n",
        "        for j in range(3):\n",
        "            line = line3.iloc[j]\n",
        "            guid = '%s-%s-%d'%(set_type, line['id'], j)\n",
        "            text_a = tokenization.convert_to_unicode(line['passage'])\n",
        "            text_b = tokenization.convert_to_unicode(line['query'])\n",
        "            if set_type == 'test':\n",
        "                label='0'\n",
        "            else:\n",
        "                label = tokenization.convert_to_unicode(str(line['label']))\n",
        "            examples.append(run_classifier.InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
        "    return examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F-LZ6vEgBlj5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "label_list = ['0', '1']\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file=VOCAB_FILE, do_lower_case=False)\n",
        "valid_examples = create_examples('valid')\n",
        "train_examples = create_examples('train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ReuBN17DrcWt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Convert training examples to features, write into tf record files"
      ]
    },
    {
      "metadata": {
        "id": "lMCEwCtyBUCb",
        "colab_type": "code",
        "outputId": "3f77f485-359c-4040-dff5-5763c5504c67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1027
        }
      },
      "cell_type": "code",
      "source": [
        "print('Please wait...')\n",
        "train_file = 'model_repo/train.tf_record'\n",
        "run_classifier.file_based_convert_examples_to_features(\n",
        "    train_examples, label_list, MAX_SEQ_LENGTH, tokenizer, train_file)\n",
        "print (f'train data written into tfrecord file: {train_file}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please wait...\n",
            "INFO:tensorflow:Writing example 0 of 750000\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-1-0\n",
            "INFO:tensorflow:tokens: [CLS] 孩 子 是 父 母 的 一 面 镜 子 由 于 儿 童 的 世 界 观 尚 未 形 成 他 们 的 模 仿 带 有 很 大 的 盲 目 性 所 以 还 是 父 母 带 好 除 非 万 不 得 已 绝 对 [SEP] 你 的 孩 子 是 保 姆 带 大 的 [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2111 2094 3221 4266 3678 4638 671 7481 7262 2094 4507 754 1036 4997 4638 686 4518 6225 2213 3313 2501 2768 800 812 4638 3563 820 2372 3300 2523 1920 4638 4683 4680 2595 2792 809 6820 3221 4266 3678 2372 1962 7370 7478 674 679 2533 2347 5318 2190 102 872 4638 2111 2094 3221 924 1990 2372 1920 4638 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-1-1\n",
            "INFO:tensorflow:tokens: [CLS] 孩 子 是 父 母 的 一 面 镜 子 由 于 儿 童 的 世 界 观 尚 未 形 成 他 们 的 模 仿 带 有 很 大 的 盲 目 性 所 以 还 是 父 母 带 好 除 非 万 不 得 已 绝 [SEP] 你 的 孩 子 不 是 保 姆 带 大 的 [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2111 2094 3221 4266 3678 4638 671 7481 7262 2094 4507 754 1036 4997 4638 686 4518 6225 2213 3313 2501 2768 800 812 4638 3563 820 2372 3300 2523 1920 4638 4683 4680 2595 2792 809 6820 3221 4266 3678 2372 1962 7370 7478 674 679 2533 2347 5318 102 872 4638 2111 2094 679 3221 924 1990 2372 1920 4638 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-1-2\n",
            "INFO:tensorflow:tokens: [CLS] 孩 子 是 父 母 的 一 面 镜 子 由 于 儿 童 的 世 界 观 尚 未 形 成 他 们 的 模 仿 带 有 很 大 的 盲 目 性 所 以 还 是 父 母 带 好 除 非 万 不 得 [SEP] 你 的 孩 子 无 法 确 定 保 姆 带 大 的 [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2111 2094 3221 4266 3678 4638 671 7481 7262 2094 4507 754 1036 4997 4638 686 4518 6225 2213 3313 2501 2768 800 812 4638 3563 820 2372 3300 2523 1920 4638 4683 4680 2595 2792 809 6820 3221 4266 3678 2372 1962 7370 7478 674 679 2533 102 872 4638 2111 2094 3187 3791 4802 2137 924 1990 2372 1920 4638 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:label: 1 (id = 1)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-2-0\n",
            "INFO:tensorflow:tokens: [CLS] 目 前 中 国 很 多 地 方 学 生 火 车 票 磁 条 都 已 经 升 级 了 在 磁 条 里 已 经 写 入 了 你 乘 车 区 间 你 在 火 车 站 售 票 处 取 票 的 时 [SEP] 不 是 一 个 区 间 刷 学 生 证 不 能 有 票 [SEP]\n",
            "INFO:tensorflow:input_ids: 101 4680 1184 704 1744 2523 1914 1765 3175 2110 4495 4125 6756 4873 4828 3340 6963 2347 5307 1285 5277 749 1762 4828 3340 7027 2347 5307 1091 1057 749 872 733 6756 1277 7313 872 1762 4125 6756 4991 1545 4873 1905 1357 4873 4638 3198 102 679 3221 671 702 1277 7313 1170 2110 4495 6395 679 5543 3300 4873 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:label: 1 (id = 1)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: train-2-1\n",
            "INFO:tensorflow:tokens: [CLS] 目 前 中 国 很 多 地 方 学 生 火 车 票 磁 条 都 已 经 升 级 了 在 磁 条 里 已 经 写 入 了 你 乘 车 区 间 你 在 火 车 站 售 票 处 取 票 的 时 候 [SEP] 不 是 一 个 区 间 刷 学 生 证 能 有 票 [SEP]\n",
            "INFO:tensorflow:input_ids: 101 4680 1184 704 1744 2523 1914 1765 3175 2110 4495 4125 6756 4873 4828 3340 6963 2347 5307 1285 5277 749 1762 4828 3340 7027 2347 5307 1091 1057 749 872 733 6756 1277 7313 872 1762 4125 6756 4991 1545 4873 1905 1357 4873 4638 3198 952 102 679 3221 671 702 1277 7313 1170 2110 4495 6395 5543 3300 4873 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:Writing example 10000 of 750000\n",
            "INFO:tensorflow:Writing example 20000 of 750000\n",
            "INFO:tensorflow:Writing example 30000 of 750000\n",
            "INFO:tensorflow:Writing example 40000 of 750000\n",
            "INFO:tensorflow:Writing example 50000 of 750000\n",
            "INFO:tensorflow:Writing example 60000 of 750000\n",
            "INFO:tensorflow:Writing example 70000 of 750000\n",
            "INFO:tensorflow:Writing example 80000 of 750000\n",
            "INFO:tensorflow:Writing example 90000 of 750000\n",
            "INFO:tensorflow:Writing example 100000 of 750000\n",
            "INFO:tensorflow:Writing example 110000 of 750000\n",
            "INFO:tensorflow:Writing example 120000 of 750000\n",
            "INFO:tensorflow:Writing example 130000 of 750000\n",
            "INFO:tensorflow:Writing example 140000 of 750000\n",
            "INFO:tensorflow:Writing example 150000 of 750000\n",
            "INFO:tensorflow:Writing example 160000 of 750000\n",
            "INFO:tensorflow:Writing example 170000 of 750000\n",
            "INFO:tensorflow:Writing example 180000 of 750000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oTlPS9Qkrk0O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Convert evaluation examples to features, write into tf record files"
      ]
    },
    {
      "metadata": {
        "id": "Ri6ENu6S_sSa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Please wait...')\n",
        "eval_file = 'model_repo/valid.tf_record'\n",
        "run_classifier.file_based_convert_examples_to_features(\n",
        "    valid_examples, label_list, MAX_SEQ_LENGTH, tokenizer, eval_file)\n",
        "print (f'valid data written into tfrecord file: {eval_file}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ln1DA7gHr_8G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Get batch input from tf record files"
      ]
    },
    {
      "metadata": {
        "id": "d56beLm_OeuL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def file_based_input_fn_builder(input_file, seq_length, is_training,\n",
        "                                drop_remainder):\n",
        "    \"\"\"Creates an `input_fn` closure to be passed to Estimator.\"\"\"\n",
        "    name_to_features = {\n",
        "          \"input_ids\": tf.FixedLenFeature([MAX_SEQ_LENGTH], tf.int64),\n",
        "          \"input_mask\": tf.FixedLenFeature([MAX_SEQ_LENGTH], tf.int64),\n",
        "          \"segment_ids\": tf.FixedLenFeature([MAX_SEQ_LENGTH], tf.int64),\n",
        "          \"label_ids\": tf.FixedLenFeature([], tf.int64),\n",
        "      }\n",
        "    def _decode_record(record, name_to_features):\n",
        "        \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
        "        example = tf.parse_single_example(record, name_to_features)\n",
        "        return example\n",
        "    def input_data (input_file=input_file, batch_size=BATCH_SIZE, drop_remainder=False):\n",
        "        d = tf.data.TFRecordDataset(input_file)\n",
        "        if is_training:\n",
        "            d = d.repeat()\n",
        "            #d = d.shuffle(buffer_size=100)\n",
        "        d = d.apply(\n",
        "            tf.data.experimental.map_and_batch(\n",
        "                lambda record: _decode_record(record, name_to_features),\n",
        "                batch_size=batch_size,\n",
        "                drop_remainder=drop_remainder))\n",
        "        return d\n",
        "\n",
        "    return input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ycJWsRETgVhW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_train_steps = int(len(train_examples) / BATCH_SIZE * epoch)\n",
        "#num_train_steps = 1e30\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "print (num_train_steps, num_warmup_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3dZbObz_xasi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Build the model"
      ]
    },
    {
      "metadata": {
        "id": "MbnNYIFfDYK3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Fine tuning model"
      ]
    },
    {
      "metadata": {
        "id": "EsR-WMEqxgbC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_model(bert_config, is_training, input_ids, input_mask, segment_ids,\n",
        "                 labels, num_labels, use_one_hot_embeddings=False):\n",
        "    \"\"\"Creates mrc model.\"\"\"\n",
        "    model = modeling.BertModel(\n",
        "        config=bert_config,\n",
        "        is_training=is_training,\n",
        "        input_ids=input_ids,\n",
        "        input_mask=input_mask,\n",
        "        token_type_ids=segment_ids,\n",
        "        use_one_hot_embeddings=use_one_hot_embeddings)\n",
        "\n",
        "    output_layer = model.get_pooled_output() # [batch*3, h]\n",
        "    \n",
        "    if is_training:\n",
        "        # I.e., 0.1 dropout\n",
        "        output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "    output_weights = tf.get_variable(\n",
        "        \"output_weights\", [1, hidden_size],\n",
        "        initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "    output_bias = tf.get_variable(\n",
        "        \"output_bias\", [1], initializer=tf.zeros_initializer())\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias) # [batch*3, 1]\n",
        "    logits = tf.reshape(logits, shape=[-1, num_labels]) # group every 3 lines together to get the softmax [batch, 3]\n",
        "    probabilities = tf.nn.softmax(logits, axis=-1) # [batch, 3]\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1) # [batch, 3]\n",
        "\n",
        "    one_hot_labels = tf.to_float(labels)\n",
        "    one_hot_labels = tf.reshape(one_hot_labels, shape=[-1, num_labels]) # group every 3 labels together to get the one hot target\n",
        "\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1) # [batch]\n",
        "    loss = tf.reduce_mean(per_example_loss) # [1]\n",
        "\n",
        "    return (loss, per_example_loss, logits, probabilities)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wJFwl5RtDcIB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Build the model function for estimator"
      ]
    },
    {
      "metadata": {
        "id": "L6mbQ3kX3mkf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_fn_builder(bert_config, num_labels, init_checkpoint, learning_rate,\n",
        "                     num_train_steps, num_warmup_steps):\n",
        "    \"\"\"Returns `model_fn` closure for Estimator.\"\"\"\n",
        "\n",
        "    def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "        \"\"\"The `model_fn` for Estimator.\"\"\"\n",
        "\n",
        "        tf.logging.info(\"*** Features ***\")\n",
        "        for name in sorted(features.keys()):\n",
        "            tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n",
        "\n",
        "        input_ids = features[\"input_ids\"]\n",
        "        input_mask = features[\"input_mask\"]\n",
        "        segment_ids = features[\"segment_ids\"]\n",
        "        label_ids = features[\"label_ids\"]\n",
        "\n",
        "        is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "        (total_loss, per_example_loss, logits, probabilities) = create_model(\n",
        "            bert_config, is_training, input_ids, input_mask, segment_ids, label_ids,\n",
        "            num_labels)\n",
        "\n",
        "        tvars = tf.trainable_variables()\n",
        "        initialized_variable_names = {}\n",
        "\n",
        "        if init_checkpoint:\n",
        "            (assignment_map, initialized_variable_names) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
        "            tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "            \n",
        "        tf.logging.info(\"**** Trainable Variables ****\")\n",
        "        for var in tvars:\n",
        "            init_string = \"\"\n",
        "            if var.name in initialized_variable_names:\n",
        "                init_string = \", *INIT_FROM_CKPT*\"\n",
        "            tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape, init_string)\n",
        "\n",
        "        output_spec = None\n",
        "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "\n",
        "            train_op = optimization.create_optimizer(total_loss, LEARNING_RATE, num_train_steps, num_warmup_steps=0, use_tpu=False)\n",
        "\n",
        "            output_spec = tf.estimator.EstimatorSpec(\n",
        "                  mode=mode,\n",
        "                  loss=total_loss,\n",
        "                  train_op=train_op)\n",
        "        elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "\n",
        "            def metric_fn(per_example_loss, label_ids, probabilities):\n",
        "                predictions = tf.argmax(probabilities, axis=-1, output_type=tf.int32)\n",
        "                labels = tf.zeros_like(predictions) # First option is always the answer\n",
        "                accuracy = tf.metrics.accuracy(label, predictions)\n",
        "                loss = tf.metrics.mean(per_example_loss)\n",
        "                return {\n",
        "                    \"eval_accuracy\": accuracy,\n",
        "                    \"eval_loss\": loss,\n",
        "                }\n",
        "\n",
        "            eval_metrics = metric_fn(per_example_loss, label_ids, probabilities)\n",
        "            output_spec = tf.estimator.EstimatorSpec(\n",
        "                  mode=mode,\n",
        "                  loss=total_loss,\n",
        "                  eval_metric_ops=eval_metrics)\n",
        "        else:\n",
        "            pred = {'class_ids': tf.argmax(probabilities, axis=-1, output_type=tf.int32),\n",
        "                'probabilities': probabilities,\n",
        "                'logits': logits,}\n",
        "            output_spec = tf.estimator.EstimatorSpec(mode=mode, predictions=pred)\n",
        "        return output_spec\n",
        "\n",
        "    return model_fn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fLilTT0nIKIY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_fn = model_fn_builder(\n",
        "      bert_config=modeling.BertConfig.from_json_file(CONFIG_FILE),\n",
        "      num_labels=3,\n",
        "      init_checkpoint=INIT_CHECKPOINT,\n",
        "      learning_rate=LEARNING_RATE,\n",
        "      num_train_steps=num_train_steps,\n",
        "      num_warmup_steps=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KRaQOI8DJMqr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "run_config = tf.estimator.RunConfig(\n",
        "      model_dir=OUTPUT_DIR,\n",
        "      save_checkpoints_steps=1000,\n",
        "      keep_checkpoint_max=2)\n",
        "\n",
        "estimator = tf.estimator.Estimator(\n",
        "      model_fn=model_fn,\n",
        "      config=run_config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HO2mKmNpEHSj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.logging.info(\"***** Running training *****\")\n",
        "tf.logging.info(\"  Num examples = %d\", len(train_examples))\n",
        "tf.logging.info(\"  Batch size = %d\", BATCH_SIZE)\n",
        "tf.logging.info(\"  Num epochs = %d\", epoch)\n",
        "train_input_fn = file_based_input_fn_builder(\n",
        "    input_file=train_file,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=False)\n",
        "estimator.train(input_fn=train_input_fn, steps=num_train_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uf0NsxIWN4bo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}