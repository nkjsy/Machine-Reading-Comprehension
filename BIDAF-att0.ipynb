{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc, random, math, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation, Dropout, Reshape, Flatten, Lambda, Permute\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import concatenate, Concatenate, multiply, Dot, dot\n",
    "from keras.layers import  GlobalMaxPooling1D, GlobalAveragePooling1D, Input, SpatialDropout1D, Bidirectional\n",
    "from keras.layers import CuDNNLSTM, CuDNNGRU, LSTM, GRU, Softmax\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 160000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen_p = 150 # max number of words in a context to use\n",
    "maxlen_q = 15 # max number of words in a question to use\n",
    "batch_size = 256\n",
    "num_rnn_units = 64\n",
    "num_hidden_units = 300\n",
    "drop_prob = 0.5\n",
    "max_norm = 5.0\n",
    "features = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = './data/train.tsv' # train set\n",
    "valid_path = './data/valid.tsv' # validation set\n",
    "test_path = './data/test.tsv' # test set\n",
    "embed_file = './sgns.target.word-ngram.1-2.dynwin5.thr10.neg5.dim300.iter5' # 预训练词向量\n",
    "fasttext_file = './cc.zh.300.vec' # 预训练词向量\n",
    "train_feature_p_path = './data/train_fea_p.npy' # train passage word feature\n",
    "valid_feature_p_path = './data/valid_fea_p.npy' # validation passage word feature\n",
    "test_feature_p_path = './data/test_fea_p.npy' # test passage word feature\n",
    "train_feature_q_path = './data/train_fea_q.npy' # train passage word feature\n",
    "valid_feature_q_path = './data/valid_fea_q.npy' # validation passage word feature\n",
    "test_feature_q_path = './data/test_fea_q.npy' # test passage word feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000, 5) (90000, 5) (29997, 4)\n",
      "   id                                            passage  \\\n",
      "0   1    是 父母 的 一面镜子   由于 儿童 的 世界观       他们 的 模仿 带有 很...   \n",
      "1   1  孩子 是 父母 的 一面镜子   由于 儿童 的 世界观       他们 的 模仿   很...   \n",
      "2   1  孩子 是 父母 的 一面镜子     儿童 的 世界观 尚未 形成   他们 的 模仿 带有...   \n",
      "3   2  目前   中国 很多 地方   学生 火车票 磁条 都 已经   了       里 已经 ...   \n",
      "4   2  目前   中国 很多 地方   学生 火车票   都 已经 升级 了   在 磁条 里 已经...   \n",
      "\n",
      "                     query option  label  \n",
      "0   无法确定 你 的 孩子 是 保姆 带 大 的   无法确定      1  \n",
      "1      是 你 的 孩子 是 保姆 带 大 的      是      0  \n",
      "2     不是 你 的 孩子 是 保姆 带 大 的     不是      0  \n",
      "3  不能 不是 一个 区间 刷 学生证 能 有 票     不能      1  \n",
      "4   能 不是 一个 区间 刷 学生证 能 有 票      能      0  \n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(train_path, sep='\\t', header=0)\n",
    "valid = pd.read_csv(valid_path, sep='\\t', header=0)\n",
    "test = pd.read_csv(test_path, sep='\\t', header=0)\n",
    "print (train.shape, valid.shape, test.shape)\n",
    "print (train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000, 150, 2) (90000, 150, 2) (29997, 150, 2)\n",
      "(750000, 15, 2) (90000, 15, 2) (29997, 15, 2)\n"
     ]
    }
   ],
   "source": [
    "train_feature_p = np.load(train_feature_p_path)\n",
    "valid_feature_p = np.load(valid_feature_p_path)\n",
    "test_feature_p = np.load(test_feature_p_path)\n",
    "print (train_feature_p.shape, valid_feature_p.shape, test_feature_p.shape)\n",
    "train_feature_q = np.load(train_feature_q_path)\n",
    "valid_feature_q = np.load(valid_feature_q_path)\n",
    "test_feature_q = np.load(test_feature_q_path)\n",
    "print (train_feature_q.shape, valid_feature_q.shape, test_feature_q.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buld up the text input pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Fit the tokenizer on train, valid and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features, lower=True) \n",
    "\n",
    "tokenizer.fit_on_texts(pd.concat([train['passage'], train['query'], valid['passage'], valid['query'], test['passage'], test['query']], ignore_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1739994 175302\n"
     ]
    }
   ],
   "source": [
    "print (tokenizer.document_count, len(tokenizer.word_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text to seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tra_p = tokenizer.texts_to_sequences(train['passage'])\n",
    "tra_q = tokenizer.texts_to_sequences(train['query'])\n",
    "val_p = tokenizer.texts_to_sequences(valid['passage'])\n",
    "val_q = tokenizer.texts_to_sequences(valid['query'])\n",
    "te_p = tokenizer.texts_to_sequences(test['passage'])\n",
    "te_q = tokenizer.texts_to_sequences(test['query'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pad seq to maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_p = pad_sequences(tra_p, maxlen=maxlen_p)\n",
    "train_q = pad_sequences(tra_q, maxlen=maxlen_q, padding='post', truncating='post')\n",
    "valid_p = pad_sequences(val_p, maxlen=maxlen_p)\n",
    "valid_q = pad_sequences(val_q, maxlen=maxlen_q, padding='post', truncating='post')\n",
    "test_p = pad_sequences(te_p, maxlen=maxlen_p)\n",
    "test_q = pad_sequences(te_q, maxlen=maxlen_q, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000, 150) (750000, 15) (90000, 150) (90000, 15) (29997, 150) (29997, 15)\n"
     ]
    }
   ],
   "source": [
    "print (train_p.shape, train_q.shape, valid_p.shape, valid_q.shape, test_p.shape, test_q.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_l = train['label']\n",
    "valid_l = valid['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000,) (90000,)\n"
     ]
    }
   ],
   "source": [
    "print (train_l.shape, valid_l.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the pretrained word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.strip().split()) for o in open(embed_file, encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.014820942, 0.26983637)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embs = np.hstack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "emb_mean,emb_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words+1, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i > max_features: break\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.asarray(embedding_matrix, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fasttext_index = dict(get_coefs(*o.strip().split()) for o in open(fasttext_file, encoding='utf-8'))\n",
    "all_ft = np.hstack(fasttext_index.values())\n",
    "ft_mean,ft_std = all_ft.mean(), all_ft.std()\n",
    "fasttext_matrix = np.random.normal(ft_mean, ft_std, (nb_words+1, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i > max_features: break\n",
    "    fasttext_vector = fasttext_index.get(word)\n",
    "    if fasttext_vector is not None: fasttext_matrix[i] = fasttext_vector\n",
    "fasttext_matrix = np.asarray(fasttext_matrix, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attention_flow (x):\n",
    "    h = x[0]\n",
    "    u = x[1]\n",
    "    s = K.batch_dot(h, K.permute_dimensions(u, (0,2,1)), axes=[2,1]) # [t, j]\n",
    "    p2q = K.batch_dot(K.softmax(s, axis=-1), u, axes=[2,1]) # [t, 2d]\n",
    "    b = K.softmax(K.max(s, axis=-1, keepdims=True), -2) # [t, 1]\n",
    "    q2p = K.tile(K.batch_dot(K.permute_dimensions(h, (0,2,1)), b, axes=[2,1]), [1, 1, K.int_shape(h)[1]]) # [2d, t]\n",
    "    h_p2q = multiply([h, p2q]) # [t, 2d]\n",
    "    h_q2p = multiply([h, K.permute_dimensions(q2p, (0,2,1))]) # [t, 2d]\n",
    "    g = concatenate([h, p2q, h_p2q, h_q2p]) # [t, 8d]\n",
    " \n",
    "    # self-attention\n",
    "    g = Activation('relu')(g) # [t, 8d]\n",
    "    gr = Bidirectional(CuDNNLSTM(num_rnn_units*4, return_sequences=True))(g) # [t, 8d]\n",
    "    sg = K.batch_dot(gr, K.permute_dimensions(gr, (0,2,1)), axes=[2,1]) # [t, t]\n",
    "    gr = K.batch_dot(K.softmax(sg, axis=-1), gr, axes=[2,1]) # [t, 8d]\n",
    "    gr = Activation('relu')(gr) # [t, 8d]\n",
    "    g = add([g, gr]) # [t, 8d]\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cos_sim (x):\n",
    "    p = x[0] # [t, 2d]\n",
    "    q = x[1] # [j, 2d]\n",
    "    s = dot([p, K.permute_dimensions(q, (0,2,1))], axes=(2,1), normalize=True) # [t, j] cosine simlilarity\n",
    "    max_sim = K.max(s, axis=-1, keepdims=True) # [t, 1]\n",
    "    return max_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def single_model():\n",
    "    p = Input(shape=(maxlen_p,))\n",
    "    q = Input(shape=(maxlen_q,))\n",
    "    p_fea = Input(shape=(maxlen_p, features)) # passage word feature \n",
    "    q_fea = Input(shape=(maxlen_q, features)) # query word feature\n",
    "    \n",
    "    # Embedding layer\n",
    "    embed = Embedding(nb_words+1, embed_size, weights=[embedding_matrix], trainable=True)\n",
    "    ft = Embedding(nb_words+1, embed_size, weights=[fasttext_matrix], trainable=True)\n",
    "    pem = embed(p) # word embedding\n",
    "    pft = ft(p)\n",
    "    pe = Concatenate()([pem, pft])\n",
    "    qem = embed(q)\n",
    "    qft = ft(q)\n",
    "    qe = Concatenate()([qem, qft])\n",
    "    \n",
    "    p_cos_e = Lambda(cos_sim)([pem, qem])\n",
    "    p_cos_f = Lambda(cos_sim)([pft, qft])\n",
    "    q_cos_e = Lambda(cos_sim)([qem, pem])\n",
    "    q_cos_f = Lambda(cos_sim)([qft, pft])\n",
    "    pe = SpatialDropout1D(0.2)(pe)\n",
    "    qe = SpatialDropout1D(0.2)(qe)\n",
    "    pf = Concatenate()([pe, p_fea, p_cos_e, p_cos_f]) # passage feature vec = word embedding + (exact match + option match + cos sim)\n",
    "    qe = Concatenate()([qe, q_fea, q_cos_e, q_cos_f]) # query feature vec = word embedding + (exact match + option match + cos sim)\n",
    "    \n",
    "    # Contextual embedding layer\n",
    "    h = Bidirectional(CuDNNLSTM(num_rnn_units, return_sequences=True))(pf) # [t, 2d]\n",
    "    u = Bidirectional(CuDNNLSTM(num_rnn_units, return_sequences=True))(qe) # [j,2d]\n",
    "    \n",
    "    # Attention flow layer\n",
    "    g = Lambda(attention_flow)([h, u]) # [t, 8d]\n",
    "    \n",
    "    # Modelling layer\n",
    "    m, hf, cf, hb, cb = Bidirectional(CuDNNLSTM(num_rnn_units, return_sequences=True, return_state=True))(g) # [t, 2d], d, d, d, d\n",
    "    #m = Bidirectional(CuDNNLSTM(num_rnn_units, return_sequences=True))(m) # [t, 2d]\n",
    "    \n",
    "    um, uhf, ucf, uhb, ucb = Bidirectional(CuDNNLSTM(num_rnn_units, return_sequences=True, return_state=True))(u) # [j,2d], d, d, d, d\n",
    "\n",
    "    # Output layer\n",
    "    conc = Concatenate()([g, m]) # [t, 10d]\n",
    "    gmp = GlobalMaxPooling1D()(conc) # [10d]\n",
    "    gap = GlobalAveragePooling1D()(conc) # [10d]\n",
    "    z1 = Concatenate()([gmp, gap, hf, hb]) # [22d]\n",
    "    \n",
    "    ugmp = GlobalMaxPooling1D()(um) # [4d]\n",
    "    ugap = GlobalAveragePooling1D()(um) # [4d]\n",
    "    z2 = Concatenate()([ugmp, ugap, uhf, uhb]) # [10d]\n",
    "\n",
    "    y = Concatenate()([z1, z2])\n",
    "    x = BatchNormalization()(y)\n",
    "    x = Dense(num_hidden_units, activation='relu')(x)\n",
    "    x = Dropout(drop_prob)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    #x = Dense(num_hidden_units, activation='relu')(x)\n",
    "    #x = Dropout(drop_prob)(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=[p, q, p_fea, q_fea], outputs=x)\n",
    "    #print (model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = single_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('./model/my6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 750000 samples, validate on 90000 samples\n",
      "Epoch 1/12\n",
      "750000/750000 [==============================] - 689s 919us/step - loss: 0.3382 - binary_accuracy: 0.8491 - val_loss: 0.4017 - val_binary_accuracy: 0.8235\n",
      "Epoch 2/12\n",
      "750000/750000 [==============================] - 690s 920us/step - loss: 0.2884 - binary_accuracy: 0.8749 - val_loss: 0.4262 - val_binary_accuracy: 0.8223\n"
     ]
    }
   ],
   "source": [
    "adam = optimizers.Adam(lr=0.0002, clipnorm=max_norm)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['binary_accuracy'])\n",
    "    \n",
    "# train the model\n",
    "cp = ModelCheckpoint(filepath='./model/my6.h5', monitor='val_binary_accuracy', save_best_only=True, save_weights_only=True)\n",
    "es = EarlyStopping(patience=0,  monitor='val_binary_accuracy')\n",
    "rp = ReduceLROnPlateau(patience = 1,  monitor='val_loss')\n",
    "hist = model.fit(\n",
    "    [train_p, train_q, train_feature_p, train_feature_q], \n",
    "    train_l,\n",
    "    batch_size = batch_size,\n",
    "    epochs = 12,\n",
    "    shuffle = True,\n",
    "    validation_data = ([valid_p, valid_q, valid_feature_p, valid_feature_q], valid_l), \n",
    "    callbacks=[rp, cp, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [0.40166734844313728, 0.42619155139393278], 'val_binary_accuracy': [0.82347777773539221, 0.82225555557674834], 'loss': [0.33816340131950379, 0.28841872950045266], 'binary_accuracy': [0.84912933332697549, 0.87491333332697552], 'lr': [0.00019999999, 0.00019999999]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x202816717f0>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (hist.history)\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(1)\n",
    "plt.plot (hist.history['binary_accuracy'])\n",
    "plt.plot (hist.history['val_binary_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the best weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('./model/my6.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = model.predict([test_p, test_q, test_feature_p, test_feature_q], batch_size=batch_size*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29997,)\n"
     ]
    }
   ],
   "source": [
    "test_pred = np.squeeze(test_pred)\n",
    "print(test_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the array into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame({'id':test['id'], 'passage':test['passage'], 'query':test['query'], 'option':test['option'], 'label':test_pred})\n",
    "res.to_csv('./result/test6_long.csv', index=False, encoding='utf-8_sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check validation prediction result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val_pred = model.predict([valid_p, valid_q, valid_feature], batch_size=batch_size*4)\n",
    "val_pred = np.squeeze(val_pred)\n",
    "res = pd.DataFrame({'id':valid['id'], 'passage':valid['passage'], 'query':valid['query'], 'option':valid['option'], 'label':val_pred})\n",
    "res.to_csv('./result/valid17_long.csv', index=False, encoding='utf-8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
