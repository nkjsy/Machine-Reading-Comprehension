{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc, random, math, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation, Dropout, Reshape, Flatten, Lambda, Permute\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import concatenate, Concatenate, multiply, Dot, subtract, add, dot\n",
    "from keras.layers import  GlobalMaxPooling1D, GlobalAveragePooling1D, Input, SpatialDropout1D, Bidirectional\n",
    "from keras.layers import CuDNNLSTM, CuDNNGRU, LSTM, GRU, Conv1D\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 160000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen_p = 150 # max number of words in a context to use\n",
    "maxlen_q = 15 # max number of words in a question to use\n",
    "batch_size = 256\n",
    "num_rnn_units = 128\n",
    "num_hidden_units = 300\n",
    "drop_prob = 0.5\n",
    "max_norm = 5.0\n",
    "features = 2\n",
    "filter_sizes_p = [1,3,5]\n",
    "filter_sizes_q = [1,3]\n",
    "num_filters = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = './data/train.tsv' # train set\n",
    "valid_path = './data/valid.tsv' # validation set\n",
    "test_path = './data/test.tsv' # test set\n",
    "embed_file = './sgns.target.word-ngram.1-2.dynwin5.thr10.neg5.dim300.iter5' # 预训练词向量\n",
    "fasttext_file = './cc.zh.300.vec' # 预训练词向量\n",
    "train_feature_p_path = './data/train_fea_p.npy' # train passage word feature\n",
    "valid_feature_p_path = './data/valid_fea_p.npy' # validation passage word feature\n",
    "test_feature_p_path = './data/test_fea_p.npy' # test passage word feature\n",
    "train_feature_q_path = './data/train_fea_q.npy' # train passage word feature\n",
    "valid_feature_q_path = './data/valid_fea_q.npy' # validation passage word feature\n",
    "test_feature_q_path = './data/test_fea_q.npy' # test passage word feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000, 5) (90000, 5) (30000, 4)\n",
      "   id                                            passage  \\\n",
      "0   1  孩子 是 父母 的 一面镜子   由于 儿童 的 世界观 尚未 形成   他们 的 模仿 带...   \n",
      "1   1  孩子 是 父母 的 一面镜子   由于 儿童 的 世界观 尚未 形成   他们 的 模仿 带...   \n",
      "2   1  孩子 是 父母 的 一面镜子   由于 儿童 的 世界观 尚未 形成   他们 的 模仿 带...   \n",
      "3   2  目前   中国 很多 地方   学生 火车票 磁条 都 已经 升级 了   在 磁条 里 已...   \n",
      "4   2  目前   中国 很多 地方   学生 火车票 磁条 都 已经 升级 了   在 磁条 里 已...   \n",
      "\n",
      "                   query option  label  \n",
      "0   你 的 孩子 无法确定 保姆 带 大 的   无法确定      1  \n",
      "1      你 的 孩子 是 保姆 带 大 的      是      0  \n",
      "2     你 的 孩子 不是 保姆 带 大 的     不是      0  \n",
      "3  不是 一个 区间 刷 学生证 不能 有 票     不能      1  \n",
      "4   不是 一个 区间 刷 学生证 能 有 票      能      0  \n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(train_path, sep='\\t', header=0)\n",
    "valid = pd.read_csv(valid_path, sep='\\t', header=0)\n",
    "test = pd.read_csv(test_path, sep='\\t', header=0)\n",
    "print (train.shape, valid.shape, test.shape)\n",
    "print (train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000, 150, 2) (90000, 150, 2) (30000, 150, 2)\n",
      "(750000, 15, 2) (90000, 15, 2) (30000, 15, 2)\n"
     ]
    }
   ],
   "source": [
    "train_feature_p = np.load(train_feature_p_path)\n",
    "valid_feature_p = np.load(valid_feature_p_path)\n",
    "test_feature_p = np.load(test_feature_p_path)\n",
    "print (train_feature_p.shape, valid_feature_p.shape, test_feature_p.shape)\n",
    "train_feature_q = np.load(train_feature_q_path)\n",
    "valid_feature_q = np.load(valid_feature_q_path)\n",
    "test_feature_q = np.load(test_feature_q_path)\n",
    "print (train_feature_q.shape, valid_feature_q.shape, test_feature_q.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buld up the text input pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Fit the tokenizer on train, valid and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features, lower=True) \n",
    "\n",
    "tokenizer.fit_on_texts(pd.concat([train['passage'], train['query'], valid['passage'], valid['query'], test['passage'], test['query']], ignore_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1740000 167520\n"
     ]
    }
   ],
   "source": [
    "print (tokenizer.document_count, len(tokenizer.word_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text to seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tra_p = tokenizer.texts_to_sequences(train['passage'])\n",
    "tra_q = tokenizer.texts_to_sequences(train['query'])\n",
    "val_p = tokenizer.texts_to_sequences(valid['passage'])\n",
    "val_q = tokenizer.texts_to_sequences(valid['query'])\n",
    "te_p = tokenizer.texts_to_sequences(test['passage'])\n",
    "te_q = tokenizer.texts_to_sequences(test['query'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pad seq to maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_p = pad_sequences(tra_p, maxlen=maxlen_p)\n",
    "train_q = pad_sequences(tra_q, maxlen=maxlen_q, padding='post', truncating='post')\n",
    "valid_p = pad_sequences(val_p, maxlen=maxlen_p)\n",
    "valid_q = pad_sequences(val_q, maxlen=maxlen_q, padding='post', truncating='post')\n",
    "test_p = pad_sequences(te_p, maxlen=maxlen_p)\n",
    "test_q = pad_sequences(te_q, maxlen=maxlen_q, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000, 150) (750000, 15) (90000, 150) (90000, 15) (30000, 150) (30000, 15)\n"
     ]
    }
   ],
   "source": [
    "print (train_p.shape, train_q.shape, valid_p.shape, valid_q.shape, test_p.shape, test_q.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_l = train['label']\n",
    "valid_l = valid['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000,) (90000,)\n"
     ]
    }
   ],
   "source": [
    "print (train_l.shape, valid_l.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the pretrained word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.strip().split()) for o in open(embed_file, encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.014820942, 0.26983637)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embs = np.hstack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "emb_mean,emb_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words+1, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i > max_features: break\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.asarray(embedding_matrix, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fasttext_index = dict(get_coefs(*o.strip().split()) for o in open(fasttext_file, encoding='utf-8'))\n",
    "all_ft = np.hstack(fasttext_index.values())\n",
    "ft_mean,ft_std = all_ft.mean(), all_ft.std()\n",
    "fasttext_matrix = np.random.normal(ft_mean, ft_std, (nb_words+1, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i > max_features: break\n",
    "    fasttext_vector = fasttext_index.get(word)\n",
    "    if fasttext_vector is not None: fasttext_matrix[i] = fasttext_vector\n",
    "fasttext_matrix = np.asarray(fasttext_matrix, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cos_sim (x):\n",
    "    p = x[0] # [t, 2d]\n",
    "    q = x[1] # [j, 2d]\n",
    "    s = dot([p, K.permute_dimensions(q, (0,2,1))], axes=(2,1), normalize=True) # [t, j] cosine simlilarity\n",
    "    max_sim = K.max(s, axis=-1, keepdims=True) # [t, 1]\n",
    "    return max_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def single_model():\n",
    "    p = Input(shape=(maxlen_p,))\n",
    "    q = Input(shape=(maxlen_q,))\n",
    "    p_fea = Input(shape=(maxlen_p, features)) # passage word feature (exact match + option match)\n",
    "    q_fea = Input(shape=(maxlen_q, features)) # query word feature\n",
    "    \n",
    "    # Embedding layer\n",
    "    embed = Embedding(nb_words+1, embed_size, weights=[embedding_matrix], trainable=True)\n",
    "    ft = Embedding(nb_words+1, embed_size, weights=[fasttext_matrix], trainable=True)\n",
    "    pem = embed(p) # word embedding\n",
    "    pft = ft(p)\n",
    "    pe = Concatenate()([pem, pft])\n",
    "    qem = embed(q)\n",
    "    qft = ft(q)\n",
    "    qe = Concatenate()([qem, qft])\n",
    "    \n",
    "    p_cos_e = Lambda(cos_sim)([pem, qem])\n",
    "    p_cos_f = Lambda(cos_sim)([pft, qft])\n",
    "    q_cos_e = Lambda(cos_sim)([qem, pem])\n",
    "    q_cos_f = Lambda(cos_sim)([qft, pft])\n",
    "    pe = SpatialDropout1D(0.2)(pe)\n",
    "    qe = SpatialDropout1D(0.2)(qe)\n",
    "    pf = Concatenate()([pe, p_fea, p_cos_e, p_cos_f]) # passage feature vec = word embedding + (exact match + option match + cos sim)\n",
    "    qe = Concatenate()([qe, q_fea, q_cos_e, q_cos_f]) # query feature vec = word embedding + (exact match + option match + cos sim)\n",
    "    \n",
    "    h = Bidirectional(CuDNNLSTM(num_rnn_units, return_sequences=True))(pf) # [t, 2d]\n",
    "    u = Bidirectional(CuDNNLSTM(num_rnn_units, return_sequences=True))(qe) # [j,2d]\n",
    "    \n",
    "    # cnn for p\n",
    "    convp_0 = Conv1D(num_filters, kernel_size=filter_sizes_p[0], padding = \"valid\", activation = 'relu')(h)\n",
    "    convp_1 = Conv1D(num_filters, kernel_size=filter_sizes_p[1], padding = \"valid\", activation = 'relu')(h)\n",
    "    convp_2 = Conv1D(num_filters, kernel_size=filter_sizes_p[2], padding = \"valid\", activation = 'relu')(h)\n",
    "\n",
    "    maxpoolp_0 = GlobalMaxPooling1D()(convp_0)\n",
    "    avgpoolp_0 = GlobalAveragePooling1D()(convp_0)\n",
    "    maxpoolp_1 = GlobalMaxPooling1D()(convp_1)\n",
    "    avgpoolp_1 = GlobalAveragePooling1D()(convp_1)\n",
    "    maxpoolp_2 = GlobalMaxPooling1D()(convp_2)\n",
    "    avgpoolp_2 = GlobalAveragePooling1D()(convp_2)\n",
    "    zp = Concatenate()([maxpoolp_0, maxpoolp_1, maxpoolp_2, avgpoolp_0, avgpoolp_1, avgpoolp_2])\n",
    "\n",
    "    # cnn for q\n",
    "    convq_0 = Conv1D(num_filters, kernel_size=filter_sizes_q[0], padding = \"valid\", activation = 'relu')(u)\n",
    "    convq_1 = Conv1D(num_filters, kernel_size=filter_sizes_q[1], padding = \"valid\", activation = 'relu')(u)\n",
    "\n",
    "    maxpoolq_0 = GlobalMaxPooling1D()(convq_0)\n",
    "    avgpoolq_0 = GlobalAveragePooling1D()(convq_0)\n",
    "    maxpoolq_1 = GlobalMaxPooling1D()(convq_1)\n",
    "    avgpoolq_1 = GlobalAveragePooling1D()(convq_1)\n",
    "    zq = Concatenate()([maxpoolq_0, maxpoolq_1, avgpoolq_0, avgpoolq_1])  \n",
    "    \n",
    "    # Output layer\n",
    "    x = Concatenate()([zp,zq])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(num_hidden_units, activation='relu')(x)\n",
    "    x = Dropout(drop_prob)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    #x = Dense(num_hidden_units, activation='relu')(x)\n",
    "    #x = Dropout(drop_prob)(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=[p, q, p_fea, q_fea], outputs=x)\n",
    "    #print (model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = single_model()\n",
    "#model.load_weights('./model/my5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 750000 samples, validate on 90000 samples\n",
      "Epoch 1/4\n",
      "750000/750000 [==============================] - 704s 939us/step - loss: 0.2911 - binary_accuracy: 0.8722 - val_loss: 0.4435 - val_binary_accuracy: 0.8241\n",
      "Epoch 2/4\n",
      "750000/750000 [==============================] - 695s 927us/step - loss: 0.2321 - binary_accuracy: 0.9001 - val_loss: 0.4940 - val_binary_accuracy: 0.8216\n"
     ]
    }
   ],
   "source": [
    "adam = optimizers.Adam(lr=0.0002, clipnorm=max_norm)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['binary_accuracy'])\n",
    "    \n",
    "# train the model\n",
    "cp = ModelCheckpoint(filepath='./model/my5.h5', monitor='val_binary_accuracy', save_best_only=True, save_weights_only=True)\n",
    "es = EarlyStopping(patience=0,  monitor='val_binary_accuracy')\n",
    "rp = ReduceLROnPlateau(patience = 1,  monitor='val_loss')\n",
    "hist = model.fit(\n",
    "    [train_p, train_q, train_feature_p, train_feature_q], \n",
    "    train_l,\n",
    "    batch_size = batch_size,\n",
    "    epochs = 4,\n",
    "    shuffle = True,\n",
    "    validation_data = ([valid_p, valid_q, valid_feature_p, valid_feature_q], valid_l), \n",
    "    callbacks=[rp, cp, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [0.4434759501563178, 0.49397632666693791], 'val_binary_accuracy': [0.82407777778837421, 0.82164444441265527], 'loss': [0.29107711356925964, 0.23208659723409017], 'binary_accuracy': [0.8721533333384196, 0.90012133333714806], 'lr': [0.00019999999, 0.00019999999]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21f7c458898>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (hist.history)\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(1)\n",
    "plt.plot (hist.history['binary_accuracy'])\n",
    "plt.plot (hist.history['val_binary_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('./model/my5.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = model.predict([test_p, test_q, test_feature_p, test_feature_q], batch_size=batch_size*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000,)\n"
     ]
    }
   ],
   "source": [
    "test_pred = np.squeeze(test_pred)\n",
    "print(test_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the array into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame({'id':test['id'], 'passage':test['passage'], 'query':test['query'], 'option':test['option'], 'label':test_pred})\n",
    "res.to_csv('./result/test5_long.csv', index=False, encoding='utf-8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
